{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4865cab4",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fde55b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8473d6c-9d4c-4faa-8d3b-75a69b82edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.precision', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c3e2f",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5196fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5v/y3sknb9x0fzg1jwjw5jw77tm0000gn/T/ipykernel_36614/3368661164.py:3: DtypeWarning: Columns (35,39,80,86) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  real_coords = pd.read_csv(\"real_estate_with_coordinates.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Import Data:\n",
    "Ames_HousePrice = pd.read_csv('Ames_HousePrice.csv', index_col=0)\n",
    "real_coords = pd.read_csv(\"real_estate_with_coordinates.csv\")\n",
    "\n",
    "# One row is duplicated in Ames_HousePrice df, once dropped there are no duplicate PID values\n",
    "Ames_HousePrice = Ames_HousePrice.drop_duplicates()\n",
    "real_coords = real_coords.drop_duplicates()\n",
    "\n",
    "# Dataframe merging\n",
    "real_estate_columns_to_keep = ['GeoRefNo','Prop_Addr', 'MA_Zip1','latitude', 'longitude']\n",
    "housing_coords = pd.merge(Ames_HousePrice, real_coords[real_estate_columns_to_keep],\n",
    "                               left_on='PID', right_on='GeoRefNo', how='left')\n",
    "\n",
    "# Remove any duplicate rows created in merge\n",
    "housing_coords = housing_coords.drop_duplicates()\n",
    "\n",
    "# Drop Columns with too many NA Values\n",
    "housing_coords.drop(['PoolQC', 'MiscFeature', 'Alley', 'Fence'],axis=1,inplace=True)\n",
    "\n",
    "# DistanceToISU column contains the distance of each property to Iowa State University\n",
    "# Coordinates of Iowa State University\n",
    "isu_latitude = 42.0239\n",
    "isu_longitude = -93.6476\n",
    "# Function to calculate Haversine distance\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Radius of the Earth in miles\n",
    "    radius = 3958.8\n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "    # Differences in latitude and longitude\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    # Haversine formula\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    # Calculate the distance\n",
    "    distance = radius * c\n",
    "    return distance\n",
    "# Calculate distance for each property address\n",
    "housing_coords['DistanceToISU'] = housing_coords.apply(\n",
    "    lambda row: haversine(row['latitude'], row['longitude'], isu_latitude, isu_longitude), axis=1)\n",
    "\n",
    "# Remove missing gps data rows:\n",
    "housing_coords = housing_coords.dropna(subset=['latitude'])\n",
    "\n",
    "# 2 rows with gps info but missing zip:\n",
    "specified_addresses = ['2010 KILDEE ST', '1310 WOODSTOCK AVE']\n",
    "# Update 'Zipcode' to 50014 where 'Address' is in the specified list\n",
    "housing_coords.loc[housing_coords['Prop_Addr'].isin(specified_addresses), 'MA_Zip1'] = 50014\n",
    "\n",
    "# Reset index after dropping rows so flitering by iloc works smoothly\n",
    "housing_coords.reset_index(drop=True,inplace=True)\n",
    "\n",
    "# This is good for EDA but since it is calculated from the target it will cause \n",
    "# data leakage and shouldn't be included in modeling\n",
    "    # # Added PricePerSF Column\n",
    "    # housing_coords['PricePerSF'] = housing_coords['SalePrice'] / housing_coords['GrLivArea']\n",
    "\n",
    "# Delete utilities column, it has 2496/2497 with same value\n",
    "    # housing_coords.Utilities.value_counts() # <-- No N/As here\n",
    "housing_coords.drop('Utilities',axis=1,inplace=True)\n",
    "\n",
    "# Fix Row with Missing Values in Basement Categories\n",
    "housing_coords.loc[housing_coords.PID==903230120,[\n",
    "    'BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n",
    "    'BsmtFullBath','BsmtHalfBath']] = housing_coords.loc[housing_coords.PID==903230120,[\n",
    "    'BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','BsmtFullBath','BsmtHalfBath']].fillna(0)\n",
    "\n",
    "# Masonry Veneer (Type/Area)\n",
    "    # If Type = 'None' but Area != 0, Type updated to mode\n",
    "    # N/As updated to None for Type and 0 for Area\n",
    "idx = (housing_coords['MasVnrArea'].isna()) & (housing_coords['MasVnrType'].isna())\n",
    "housing_coords.loc[idx, 'MasVnrArea'] = housing_coords.loc[idx, 'MasVnrArea'].fillna(0)\n",
    "housing_coords.loc[idx, 'MasVnrType'] = housing_coords.loc[idx, 'MasVnrType'].fillna('None')\n",
    "mode_MasVnrType = housing_coords.loc[housing_coords.MasVnrType!='None'].MasVnrType.mode()[0]\n",
    "idx2 = (housing_coords['MasVnrArea']!=0) & (housing_coords['MasVnrType']== 'None')\n",
    "housing_coords.loc[idx2, 'MasVnrType'] = housing_coords.loc[idx2, 'MasVnrType'].fillna(mode_MasVnrType)\n",
    "\n",
    "# Fix Row with Missing Values in GarageCars & GarageArea Categories\n",
    "idx3 = (housing_coords['GarageArea']!=0) & (housing_coords['GarageType']=='Detchd')\n",
    "mean_GarageArea = round(housing_coords.loc[idx3, 'GarageArea'].mean())\n",
    "housing_coords.loc[housing_coords.PID==910201180,'GarageArea'] = mean_GarageArea\n",
    "idx4 = housing_coords['GarageType']=='Detchd'\n",
    "mode_GarageCars = housing_coords.loc[idx4, 'GarageCars'].mode()[0]\n",
    "housing_coords.loc[housing_coords.PID==910201180,'GarageCars'] = mode_GarageCars\n",
    "\n",
    "# Fill GarageYrBlt to match Year House Was Built\n",
    "housing_coords['GarageYrBlt'] = housing_coords['GarageYrBlt'].fillna(housing_coords['YearBuilt']) # 129 N/A\n",
    "\n",
    "# Fix Row where Year Remodeled occured before Year Built\n",
    "housing_coords.loc[housing_coords.PID==907194160,'YearRemodAdd'] = \\\n",
    "housing_coords.loc[housing_coords.PID==907194160,'YearBuilt']\n",
    "\n",
    "# Fill with Most Common (Categorical) Value:\n",
    "mode_Electrical = housing_coords['Electrical'].mode()[0] # 1 N/A\n",
    "housing_coords['Electrical'].fillna(mode_Electrical, inplace=True)\n",
    "\n",
    "# 451 N/A values for Lot Frontage\n",
    "    # The average ratio of LotFrontage/LotArea was calculated for each\n",
    "    # LotType & LotShape and this percentage factor was used to calculate\n",
    "    # The missing LotFrontage Values (since LotArea was not missing)\n",
    "lot_df = housing_coords.loc[housing_coords['LotFrontage'].notna()][[\n",
    "    'LotFrontage','LotArea','LotConfig','LotShape']]\n",
    "lot_df2 = lot_df.groupby(['LotConfig','LotShape']).agg({'LotFrontage':'mean','LotArea':'mean'})\n",
    "lot_df2['PCT_Frontage']=lot_df2['LotFrontage']/lot_df2['LotArea']\n",
    "percentage_factor_mapping = lot_df2['PCT_Frontage'].to_dict()\n",
    "\n",
    "# Update the NaN values in 'LotFrontage' using the mapping and LotArea\n",
    "housing_coords['LotFrontage'] = housing_coords.apply(\n",
    "    lambda row: round(row['LotArea'] * percentage_factor_mapping.get(\n",
    "        (row['LotConfig'], row['LotShape']), 1.0)), axis=1)\n",
    "\n",
    "# Combine Full and Half Bathroom Categories\n",
    "housing_coords['BsmtBath']=housing_coords['BsmtFullBath']+0.5*housing_coords['BsmtHalfBath']\n",
    "housing_coords['Bath']=housing_coords['FullBath']+0.5*housing_coords['HalfBath']\n",
    "housing_coords.drop(['BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath'],axis=1,inplace=True)\n",
    "\n",
    "# Replace TotRmsAbvGrd with MiscRmsAbvGrd to avoid multicollinearity?\n",
    "# These are not bedroom, kitchen, nor bathroom\n",
    "housing_coords['MiscRmsAbvGrd'] = housing_coords.TotRmsAbvGrd - housing_coords.BedroomAbvGr - housing_coords.KitchenAbvGr\n",
    "    # Drop This?\n",
    "    # housing_coords.drop('TotRmsAbvGrd',axis=1,inplace=True)\n",
    "\n",
    "# Change YearBuilt to Age so it works better as a numerical variable\n",
    "housing_coords['Age'] = housing_coords['YrSold'] - housing_coords['YearBuilt']\n",
    "housing_coords.drop('YearBuilt',axis=1,inplace=True)\n",
    "\n",
    "# Fill NaN with 'None' for categorical columns\n",
    "categorical_features = ['FireplaceQu', 'GarageCond','GarageQual','GarageFinish', \n",
    "                        'GarageType', 'BsmtQual', 'BsmtCond', 'BsmtFinType1', \n",
    "                        'BsmtFinType2', 'BsmtExposure']\n",
    "housing_coords[categorical_features] = housing_coords[categorical_features].fillna('None')\n",
    "\n",
    "# Drop PID & GeoRefNo. They are only needed for merging\n",
    "housing_coords.drop(['GeoRefNo', 'PID'],axis=1,inplace=True)\n",
    "\n",
    "# Replace MSSubClass numerical values with letter values since it is categorical\n",
    "MSSubClass_mapping_dict = {20:'A', 30:'B', 40:'C', 45:'D', 50:'E', 60:'F', 70:'G', 75:'H', \n",
    "                           80:'I', 85:'J', 90:'K', 120:'L', 150:'M', 160:'N', 180:'O', 190:'P'}\n",
    "housing_coords['MSSubClass'] = housing_coords['MSSubClass'].replace(MSSubClass_mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251447ca",
   "metadata": {},
   "source": [
    "# Import Libraries (for ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab765e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import f_regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7799d923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: [[237.20457049]]\n",
      "Intercept: [67513.35712606]\n",
      "R-squared: 0.3976483333076949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fecd958d7e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the dataset into a training set and a test set\n",
    "X = housing_coords[['GarageArea']]  # Feature(s)\n",
    "y = housing_coords[['SalePrice']]  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "# Create a Linear Regression model\n",
    "lm = LinearRegression()\n",
    "\n",
    "# Fit the model with the training data\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "# Print the coefficients and intercept\n",
    "print(\"Coefficient:\", lm.coef_)\n",
    "print(\"Intercept:\", lm.intercept_)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "lm_r2_score = lm.score(X_test, y_test)\n",
    "print(\"R-squared:\", lm_r2_score)\n",
    "\n",
    "plt.scatter(y_pred,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "33060efa-17a5-47a5-8342-cc9d6a3ee706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>Prop_Addr</th>\n",
       "      <th>MA_Zip1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>DistanceToISU</th>\n",
       "      <th>BsmtBath</th>\n",
       "      <th>Bath</th>\n",
       "      <th>MiscRmsAbvGrd</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [GrLivArea, SalePrice, MSSubClass, MSZoning, LotFrontage, LotArea, Street, LotShape, LandContour, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearRemodAdd, RoofStyle, RoofMatl, Exterior1st, Exterior2nd, MasVnrType, MasVnrArea, ExterQual, ExterCond, Foundation, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinSF1, BsmtFinType2, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, Heating, HeatingQC, CentralAir, Electrical, 1stFlrSF, 2ndFlrSF, LowQualFinSF, BedroomAbvGr, KitchenAbvGr, KitchenQual, TotRmsAbvGrd, Functional, Fireplaces, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageCars, GarageArea, GarageQual, GarageCond, PavedDrive, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal, MoSold, YrSold, SaleType, SaleCondition, Prop_Addr, MA_Zip1, latitude, longitude, DistanceToISU, BsmtBath, Bath, MiscRmsAbvGrd, Age]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 79 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_coords.loc[housing_coords.BsmtBath.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0f00d05c-8b69-441a-9878-4a89350e71f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numeric columns\n",
    "numeric_columns = housing_coords.select_dtypes(include='number')\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "sorted_corrs = (numeric_columns.corr()['SalePrice']).sort_values(ascending=False).drop(['SalePrice'])\n",
    "categorical_columns = list(set(housing_coords.columns) - set(numeric_columns.corr()['SalePrice'].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa8d9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverallQual\n",
      "R-squared: 0.6051802286986979 \n",
      "\n",
      "GrLivArea\n",
      "R-squared: 0.4730303791982675 \n",
      "\n",
      "TotalBsmtSF\n",
      "R-squared: 0.44640246996413324 \n",
      "\n",
      "1stFlrSF\n",
      "R-squared: 0.41808102243737955 \n",
      "\n",
      "GarageCars\n",
      "R-squared: 0.4095256245974921 \n",
      "\n",
      "GarageArea\n",
      "R-squared: 0.3976483333076949 \n",
      "\n",
      "MiscRmsAbvGrd\n",
      "R-squared: 0.33333486428682957 \n",
      "\n",
      "Bath\n",
      "R-squared: 0.37202040186298013 \n",
      "\n",
      "GarageYrBlt\n",
      "R-squared: 0.24669539073168711 \n",
      "\n",
      "YearRemodAdd\n",
      "R-squared: 0.2095396534409576 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fece093a140>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in sorted_corrs.index[:10]:\n",
    "    # Split the dataset into a training set and a test set\n",
    "    X = housing_coords[[i]]  # Feature(s)\n",
    "    y = housing_coords[['SalePrice']]  # Target variable\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "    # Create a Linear Regression model\n",
    "    lm = LinearRegression()\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    lm.fit(X_train, y_train)\n",
    "\n",
    "    # Print the coefficients and intercept\n",
    "#     print(\"Coefficient:\", lm.coef_)\n",
    "#     print(\"Intercept:\", lm.intercept_)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = lm.predict(X_test)\n",
    "\n",
    "    # Calculate the R-squared score\n",
    "    lr_r2_score = lm.score(X_test, y_test)\n",
    "    print(i)\n",
    "    print(\"R-squared:\", lr_r2_score,'\\n')\n",
    "plt.scatter(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6402ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression with 80/20 train/test split\n",
      "Features Used: ['OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'GarageCars', 'GarageArea', 'MiscRmsAbvGrd', 'Bath', 'GarageYrBlt', 'YearRemodAdd'] \n",
      "\n",
      "Mean Squared Error: 869949196.995385\n",
      "R-squared (R2) Score: 0.8142713896287384\n"
     ]
    }
   ],
   "source": [
    "feature_columns = sorted_corrs.index[:10]\n",
    "\n",
    "# Extract features and target variable\n",
    "X = housing_coords[feature_columns]\n",
    "y = housing_coords['SalePrice']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (optional, but often recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Linear Regression with 80/20 train/test split')\n",
    "print(f'Features Used: {list(feature_columns)}','\\n')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared (R2) Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OverallQual', 'GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'GarageCars',\n",
       "       'GarageArea', 'MiscRmsAbvGrd', 'Bath', 'GarageYrBlt', 'YearRemodAdd',\n",
       "       'TotRmsAbvGrd', 'MasVnrArea', 'Fireplaces', 'BsmtFinSF1', 'WoodDeckSF',\n",
       "       'OpenPorchSF', 'BsmtBath', 'latitude', 'LotArea', '2ndFlrSF',\n",
       "       'DistanceToISU', 'BsmtUnfSF', 'BedroomAbvGr', 'ScreenPorch',\n",
       "       'LotFrontage', '3SsnPorch', 'PoolArea', 'BsmtFinSF2', 'MoSold',\n",
       "       'YrSold', 'MA_Zip1', 'MiscVal', 'LowQualFinSF', 'KitchenAbvGr',\n",
       "       'OverallCond', 'EnclosedPorch', 'longitude', 'Age'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_corrs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d38541-9daf-41db-a240-d5064f7e1934",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list(sorted_corrs.index)\n",
    "test2 = list(sorted_corrs.index)\n",
    "\n",
    "test.remove('GrLivArea')\n",
    "test.remove('TotalBsmtSF')\n",
    "\n",
    "test2.remove('1stFlrSF')\n",
    "test2.remove('2ndFlrSF')\n",
    "test2.remove('LowQualFinSF')\n",
    "test2.remove('BsmtFinSF1')\n",
    "test2.remove('BsmtFinSF2')\n",
    "test2.remove('BsmtUnfSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340d84a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/20 train/test split\n",
      "Features Used: ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'GarageArea', 'MiscRmsAbvGrd', 'Bath', 'GarageYrBlt', 'YearRemodAdd', 'TotRmsAbvGrd'] \n",
      "\n",
      "Linear Regression:\n",
      "Mean Squared Error: 819219047.7162697\n",
      "R-squared (R2) Score: 0.8251019532548425\n",
      "\n",
      "Ridge Regression:\n",
      "Alpha = 1 (determined from grid search)\n",
      "Mean Squared Error: 818845381.2914228\n",
      "R-squared (R2) Score: 0.8251817286556002\n",
      "\n",
      "Lasso Regression:\n",
      "Alpha = 1 (determined from grid search)\n",
      "Mean Squared Error: 819187122.3467519\n",
      "R-squared (R2) Score: 0.8251087691178108\n",
      "\n",
      "Ridge Coefficients: [ 22316.44891493  36956.47971557  17654.80486712   1247.78219204\n",
      "   6628.34468665  14066.02116529  -5271.35436046   5015.16243844\n",
      "   6203.01350608 -17411.88021213]\n",
      "Ridge Intercept: 178817.7711567351\n",
      "\n",
      "Lasso Coefficients: [ 22310.9930274   37055.95581573  17648.97827231   1235.98043292\n",
      "   6621.81053611  14101.16447623  -5297.4843194    5025.76383497\n",
      "   6198.50914942 -17503.52042545]\n",
      "Lasso Intercept: 178817.7711567351\n"
     ]
    }
   ],
   "source": [
    "feature_columns = sorted_corrs.index[0:10]\n",
    "# feature_columns = VIF_columns\n",
    "# Removing the columns with overlapping features Greatly lowered R2 values...\n",
    "# feature_columns = test[:10]\n",
    "feature_columns = test2[:10]\n",
    "\n",
    "# Extract features and target variable\n",
    "X = housing_coords[feature_columns]\n",
    "y = housing_coords['SalePrice']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (optional, but often recommended)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train_scaled, y_train)\n",
    "y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "\n",
    "# Set up parameter grids for Ridge and Lasso\n",
    "alpha_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Perform GridSearchCV for Ridge\n",
    "ridge_model = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge_model, alpha_params, scoring='neg_mean_squared_error', cv=5)\n",
    "ridge_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Perform GridSearchCV for Lasso\n",
    "lasso_model = Lasso()\n",
    "lasso_grid = GridSearchCV(lasso_model, alpha_params, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best alpha values\n",
    "best_alpha_ridge = ridge_grid.best_params_['alpha']\n",
    "best_alpha_lasso = lasso_grid.best_params_['alpha']\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model_best = Ridge(alpha=best_alpha_ridge)\n",
    "ridge_model_best.fit(X_train_scaled, y_train)\n",
    "y_pred_ridge = ridge_model_best.predict(X_test_scaled)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model_best = Lasso(alpha=best_alpha_lasso)  # You can adjust the alpha parameter for regularization strength\n",
    "lasso_model_best.fit(X_train_scaled, y_train)\n",
    "y_pred_lasso = lasso_model_best.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the models\n",
    "mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "\n",
    "print('80/20 train/test split')\n",
    "print(f'Features Used: {list(feature_columns)}','\\n')\n",
    "\n",
    "print('Linear Regression:')\n",
    "print(f'Mean Squared Error: {mse_linear}')\n",
    "print(f'R-squared (R2) Score: {r2_linear}')\n",
    "\n",
    "print('\\nRidge Regression:')\n",
    "print(f'Alpha = {best_alpha_ridge} (determined from grid search)')\n",
    "print(f'Mean Squared Error: {mse_ridge}')\n",
    "print(f'R-squared (R2) Score: {r2_ridge}')\n",
    "\n",
    "print('\\nLasso Regression:')\n",
    "print(f'Alpha = {best_alpha_lasso} (determined from grid search)')\n",
    "print(f'Mean Squared Error: {mse_lasso}')\n",
    "print(f'R-squared (R2) Score: {r2_lasso}')\n",
    "\n",
    "print('\\nRidge Coefficients:', ridge_model_best.coef_)\n",
    "print('Ridge Intercept:', ridge_model_best.intercept_)\n",
    "\n",
    "print('\\nLasso Coefficients:', lasso_model_best.coef_)\n",
    "print('Lasso Intercept:', lasso_model_best.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119167c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.394e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.724e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.881e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.015e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.059e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.463e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.370e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.825e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.205e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.003e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.161e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.772e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.062e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.327e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.627e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.384e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.721e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.882e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.015e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.058e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.437e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.379e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.379e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.203e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.952e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.184e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.825e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.097e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.221e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.616e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.364e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.704e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.869e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.987e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.040e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.391e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.364e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.819e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.325e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.958e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.179e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.699e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.019e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.286e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.971e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.555e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.113e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.688e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.816e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.956e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.904e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.563e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.260e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.105e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.723e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.265e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.703e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.490e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.346e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.842e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.856e+09, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.946e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.093e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.063e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.061e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.662e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.786e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.889e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.620e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.230e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.692e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.501e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.047e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.555e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.468e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.082e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.613e+09, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.382e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.532e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.048e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.786e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.902e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.887e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.626e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.228e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.116e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.693e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.498e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.871e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.046e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.081e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.604e+09, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.402e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.418e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.048e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.785e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.886e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.628e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.229e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.115e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.692e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.495e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.050e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.559e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.471e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.071e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+09, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.403e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.543e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.414e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.660e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.783e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.896e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.887e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.667e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.232e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.111e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.694e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.504e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.953e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.059e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.554e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.520e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.133e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.740e+09, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.375e+09, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.721e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.432e+09, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.355e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.693e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.835e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.996e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.567e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.827e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.663e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.238e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.973e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.925e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.366e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.391e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.372e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.731e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.486e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.349e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.687e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.835e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.909e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.995e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.620e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.562e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.656e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.827e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.663e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.848e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.235e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.719e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.972e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.814e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.914e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.365e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.740e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.385e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.366e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.730e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.828e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.487e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.344e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.680e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.904e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.991e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.613e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.555e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.653e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.822e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.657e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.224e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.717e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.974e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.805e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.905e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.135e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.380e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.360e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.728e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.824e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.480e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.340e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.680e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.832e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.990e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.610e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.554e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.652e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.842e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.225e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.718e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.897e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.727e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.821e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.476e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.340e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.679e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.830e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.901e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.990e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.610e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.553e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.651e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.820e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.655e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.843e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.226e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.715e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.975e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.801e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.252e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.362e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.745e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.134e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.376e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.359e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.726e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.821e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.476e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.722e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.992e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.517e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.201e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.736e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.672e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.769e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.909e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.804e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.705e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.681e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.073e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.838e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.812e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.704e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.684e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.094e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.284e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.262e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.367e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.383e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.408e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.283e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.104e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.168e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.284e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.302e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.286e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.276e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.352e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.375e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.397e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.085e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.276e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.087e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.138e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.259e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.278e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.304e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.621e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.380e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.256e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.134e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.275e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.301e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.136e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.259e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.277e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.303e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.239e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.620e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.381e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.074e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.246e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.262e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.076e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.120e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.248e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.264e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.291e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.260e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.594e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.353e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.374e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.249e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.039e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.084e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.207e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.228e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.250e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.041e+11, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e+11, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e+11, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.230e+11, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.252e+11, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.238e+10, tolerance: 9.107e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.210e+10, tolerance: 9.398e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.308e+10, tolerance: 9.516e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.332e+10, tolerance: 9.264e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.349e+10, tolerance: 9.630e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(sorted_corrs.index)):\n",
    "    # Removing the columns with overlapping features Greatly lowered R2 values...\n",
    "    # feature_columns = test[:10]\n",
    "    # feature_columns = test2[:10]\n",
    "    feature_columns = sorted_corrs.index[0:i+1]\n",
    "\n",
    "    # Extract features and target variable\n",
    "    X = housing_coords[feature_columns]\n",
    "    y = housing_coords['SalePrice']\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the features (optional, but often recommended)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Linear Regression\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train_scaled, y_train)\n",
    "    y_pred_linear = linear_model.predict(X_test_scaled)\n",
    "\n",
    "    # Set up parameter grids for Ridge and Lasso\n",
    "    alpha_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "    # Perform GridSearchCV for Ridge\n",
    "    ridge_model = Ridge()\n",
    "    ridge_grid = GridSearchCV(ridge_model, alpha_params, scoring='neg_mean_squared_error', cv=5)\n",
    "    ridge_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Perform GridSearchCV for Lasso\n",
    "    lasso_model = Lasso()\n",
    "    lasso_grid = GridSearchCV(lasso_model, alpha_params, scoring='neg_mean_squared_error', cv=5)\n",
    "    lasso_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Get the best alpha values\n",
    "    best_alpha_ridge = ridge_grid.best_params_['alpha']\n",
    "    best_alpha_lasso = lasso_grid.best_params_['alpha']\n",
    "\n",
    "    # Ridge Regression\n",
    "    ridge_model_best = Ridge(alpha=best_alpha_ridge)\n",
    "    ridge_model_best.fit(X_train_scaled, y_train)\n",
    "    y_pred_ridge = ridge_model_best.predict(X_test_scaled)\n",
    "\n",
    "    # Lasso Regression\n",
    "    lasso_model_best = Lasso(alpha=best_alpha_lasso)  # You can adjust the alpha parameter for regularization strength\n",
    "    lasso_model_best.fit(X_train_scaled, y_train)\n",
    "    y_pred_lasso = lasso_model_best.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the models\n",
    "    mse_linear = mean_squared_error(y_test, y_pred_linear)\n",
    "    r2_linear = r2_score(y_test, y_pred_linear)\n",
    "\n",
    "    mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "    r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "    mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "    r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "\n",
    "#     print('80/20 train/test split')\n",
    "#     print(f'Features Used: {list(feature_columns)}','\\n')\n",
    "#     print('TEST2\\n\\n')\n",
    "#     print('Linear Regression:')\n",
    "#     print(f'Mean Squared Error: {mse_linear}')\n",
    "#     print(f'R-squared (R2) Score: {r2_linear}')\n",
    "\n",
    "#     print('\\nRidge Regression:')\n",
    "#     print(f'Alpha = {best_alpha_ridge} (determined from grid search)')\n",
    "#     print(f'Mean Squared Error: {mse_ridge}')\n",
    "#     print(f'R-squared (R2) Score: {r2_ridge}')\n",
    "\n",
    "#     print('\\nLasso Regression:')\n",
    "#     print(f'Alpha = {best_alpha_lasso} (determined from grid search)')\n",
    "#     print(f'Mean Squared Error: {mse_lasso}')\n",
    "#     print(f'R-squared (R2) Score: {r2_lasso}')\n",
    "\n",
    "    # print('\\nRidge Coefficients:', ridge_model_best.coef_)\n",
    "    # print('Ridge Intercept:', ridge_model_best.intercept_)\n",
    "\n",
    "    # print('\\nLasso Coefficients:', lasso_model_best.coef_)\n",
    "    # print('Lasso Intercept:', lasso_model_best.intercept_)\n",
    "    \n",
    "    # Append results to the list\n",
    "    results_list.append({\n",
    "        'Features Used': list(feature_columns),\n",
    "        'Linear Regression R2': r2_linear,\n",
    "        'Ridge Regression R2': r2_ridge, \n",
    "        'Lasso Regression R2': r2_lasso\n",
    "    })\n",
    "\n",
    "# Create a data frame from the list of results\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Print or use the data frame as needed\n",
    "# print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe0df70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Linear Regression R2</th>\n",
       "      <th>Ridge Regression R2</th>\n",
       "      <th>Lasso Regression R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[OverallQual]</td>\n",
       "      <td>0.60518</td>\n",
       "      <td>0.60518</td>\n",
       "      <td>0.60518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OverallQual, GrLivArea]</td>\n",
       "      <td>0.70856</td>\n",
       "      <td>0.70860</td>\n",
       "      <td>0.70857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF]</td>\n",
       "      <td>0.78189</td>\n",
       "      <td>0.78192</td>\n",
       "      <td>0.78191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF]</td>\n",
       "      <td>0.78091</td>\n",
       "      <td>0.78111</td>\n",
       "      <td>0.78092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.79458</td>\n",
       "      <td>0.79478</td>\n",
       "      <td>0.79460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.79890</td>\n",
       "      <td>0.79909</td>\n",
       "      <td>0.79907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>0.80394</td>\n",
       "      <td>0.80377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.80190</td>\n",
       "      <td>0.80240</td>\n",
       "      <td>0.80197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.80452</td>\n",
       "      <td>0.80521</td>\n",
       "      <td>0.80452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.81427</td>\n",
       "      <td>0.81491</td>\n",
       "      <td>0.81427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.82414</td>\n",
       "      <td>0.82420</td>\n",
       "      <td>0.82421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.82871</td>\n",
       "      <td>0.82908</td>\n",
       "      <td>0.82877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.82943</td>\n",
       "      <td>0.82975</td>\n",
       "      <td>0.82999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84618</td>\n",
       "      <td>0.84666</td>\n",
       "      <td>0.84623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84467</td>\n",
       "      <td>0.84510</td>\n",
       "      <td>0.84472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84457</td>\n",
       "      <td>0.84505</td>\n",
       "      <td>0.84520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84473</td>\n",
       "      <td>0.84520</td>\n",
       "      <td>0.84537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84452</td>\n",
       "      <td>0.84497</td>\n",
       "      <td>0.84515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84929</td>\n",
       "      <td>0.84968</td>\n",
       "      <td>0.84979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85023</td>\n",
       "      <td>0.85040</td>\n",
       "      <td>0.85028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85016</td>\n",
       "      <td>0.85033</td>\n",
       "      <td>0.85046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85038</td>\n",
       "      <td>0.85051</td>\n",
       "      <td>0.85069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85225</td>\n",
       "      <td>0.85117</td>\n",
       "      <td>0.85215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85207</td>\n",
       "      <td>0.85101</td>\n",
       "      <td>0.85197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>0.84899</td>\n",
       "      <td>0.85122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>0.84899</td>\n",
       "      <td>0.85122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85143</td>\n",
       "      <td>0.84892</td>\n",
       "      <td>0.84953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85143</td>\n",
       "      <td>0.84873</td>\n",
       "      <td>0.84932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.84876</td>\n",
       "      <td>0.84931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85081</td>\n",
       "      <td>0.84817</td>\n",
       "      <td>0.84886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85076</td>\n",
       "      <td>0.84808</td>\n",
       "      <td>0.84881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85062</td>\n",
       "      <td>0.84787</td>\n",
       "      <td>0.84869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85066</td>\n",
       "      <td>0.85028</td>\n",
       "      <td>0.84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85064</td>\n",
       "      <td>0.85054</td>\n",
       "      <td>0.85212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85283</td>\n",
       "      <td>0.85260</td>\n",
       "      <td>0.85465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.85282</td>\n",
       "      <td>0.85472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85481</td>\n",
       "      <td>0.85500</td>\n",
       "      <td>0.85562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86052</td>\n",
       "      <td>0.85982</td>\n",
       "      <td>0.86234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Features Used  Linear Regression R2  \\\n",
       "0                                       [OverallQual]               0.60518   \n",
       "1                            [OverallQual, GrLivArea]               0.70856   \n",
       "2               [OverallQual, GrLivArea, TotalBsmtSF]               0.78189   \n",
       "3     [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF]               0.78091   \n",
       "4   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.79458   \n",
       "5   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.79890   \n",
       "6   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.80375   \n",
       "7   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.80190   \n",
       "8   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.80452   \n",
       "9   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.81427   \n",
       "10  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.82414   \n",
       "11  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.82871   \n",
       "12  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.82943   \n",
       "13  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84618   \n",
       "14  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84467   \n",
       "15  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84457   \n",
       "16  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84473   \n",
       "17  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84452   \n",
       "18  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84929   \n",
       "19  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85023   \n",
       "20  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85016   \n",
       "21  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85038   \n",
       "22  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85225   \n",
       "23  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85207   \n",
       "24  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85137   \n",
       "25  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85137   \n",
       "26  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85143   \n",
       "27  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85143   \n",
       "28  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85135   \n",
       "29  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85081   \n",
       "30  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85076   \n",
       "31  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85062   \n",
       "32  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85066   \n",
       "33  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85064   \n",
       "34  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85283   \n",
       "35  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85300   \n",
       "36  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85481   \n",
       "37  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86052   \n",
       "\n",
       "    Ridge Regression R2  Lasso Regression R2  \n",
       "0               0.60518              0.60518  \n",
       "1               0.70860              0.70857  \n",
       "2               0.78192              0.78191  \n",
       "3               0.78111              0.78092  \n",
       "4               0.79478              0.79460  \n",
       "5               0.79909              0.79907  \n",
       "6               0.80394              0.80377  \n",
       "7               0.80240              0.80197  \n",
       "8               0.80521              0.80452  \n",
       "9               0.81491              0.81427  \n",
       "10              0.82420              0.82421  \n",
       "11              0.82908              0.82877  \n",
       "12              0.82975              0.82999  \n",
       "13              0.84666              0.84623  \n",
       "14              0.84510              0.84472  \n",
       "15              0.84505              0.84520  \n",
       "16              0.84520              0.84537  \n",
       "17              0.84497              0.84515  \n",
       "18              0.84968              0.84979  \n",
       "19              0.85040              0.85028  \n",
       "20              0.85033              0.85046  \n",
       "21              0.85051              0.85069  \n",
       "22              0.85117              0.85215  \n",
       "23              0.85101              0.85197  \n",
       "24              0.84899              0.85122  \n",
       "25              0.84899              0.85122  \n",
       "26              0.84892              0.84953  \n",
       "27              0.84873              0.84932  \n",
       "28              0.84876              0.84931  \n",
       "29              0.84817              0.84886  \n",
       "30              0.84808              0.84881  \n",
       "31              0.84787              0.84869  \n",
       "32              0.85028              0.84900  \n",
       "33              0.85054              0.85212  \n",
       "34              0.85260              0.85465  \n",
       "35              0.85282              0.85472  \n",
       "36              0.85500              0.85562  \n",
       "37              0.85982              0.86234  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5f67df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting Linear Regression R2\n",
    "plt.plot(range(1, len(results_df) + 1), results_df['Linear Regression R2'], label='Linear Regression')\n",
    "\n",
    "# Plotting Ridge Regression R2\n",
    "plt.plot(range(1, len(results_df) + 1), results_df['Ridge Regression R2'], label='Ridge Regression')\n",
    "\n",
    "# Plotting Lasso Regression R2\n",
    "plt.plot(range(1, len(results_df) + 1), results_df['Lasso Regression R2'], label='Lasso Regression')\n",
    "\n",
    "plt.title('R-squared (R2) vs. Number of Features')\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('R-squared (R2)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f404e182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickherman/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:198: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "# Display the VIF values\n",
    "# vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e46ab313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Specify the number of folds (e.g., k=5 for 5-fold cross-validation)\n",
    "k_folds = 5\n",
    "\n",
    "# Create a k-fold cross-validator\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for i in range(len(sorted_corrs.index)):\n",
    "# for i in range(20):\n",
    "    feature_columns = sorted_corrs.index[0:i+1]\n",
    "\n",
    "    X = housing_coords[feature_columns]\n",
    "    y = housing_coords['SalePrice']\n",
    "\n",
    "    # Standardize the features (optional, but often recommended)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Linear Regression\n",
    "    linear_model = LinearRegression()\n",
    "\n",
    "    # Use cross_val_score for k-fold cross-validation\n",
    "    r2_scores = cross_val_score(linear_model, X_scaled, y, scoring='r2', cv=kf)\n",
    "\n",
    "    # Append results to the list\n",
    "    results_list.append({\n",
    "        'Features Used': list(feature_columns),\n",
    "        'Linear Regression R2': r2_scores.mean(),  # Use the average R2 score from cross-validation\n",
    "        'Fold 1 R2': r2_scores[0],\n",
    "        'Fold 2 R2': r2_scores[1], \n",
    "        'Fold 3 R2': r2_scores[2], \n",
    "        'Fold 4 R2': r2_scores[3], \n",
    "        'Fold 5 R2': r2_scores[4], \n",
    "        'Standard Deviation':r2_scores.std()\n",
    "    })\n",
    "\n",
    "# Create a data frame from the list of results\n",
    "KF_results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d485d5-d855-43db-b6b3-7ab651bc100d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f12201-3d00-4ed8-84b7-3b05a32359c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69d3079b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features Used</th>\n",
       "      <th>Linear Regression R2</th>\n",
       "      <th>Fold 1 R2</th>\n",
       "      <th>Fold 2 R2</th>\n",
       "      <th>Fold 3 R2</th>\n",
       "      <th>Fold 4 R2</th>\n",
       "      <th>Fold 5 R2</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[OverallQual]</td>\n",
       "      <td>0.62823</td>\n",
       "      <td>0.60518</td>\n",
       "      <td>0.62770</td>\n",
       "      <td>0.66175</td>\n",
       "      <td>0.61486</td>\n",
       "      <td>0.63167</td>\n",
       "      <td>0.01921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[OverallQual, GrLivArea]</td>\n",
       "      <td>0.74339</td>\n",
       "      <td>0.70856</td>\n",
       "      <td>0.74304</td>\n",
       "      <td>0.76797</td>\n",
       "      <td>0.73839</td>\n",
       "      <td>0.75898</td>\n",
       "      <td>0.02042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF]</td>\n",
       "      <td>0.80008</td>\n",
       "      <td>0.78189</td>\n",
       "      <td>0.79559</td>\n",
       "      <td>0.81254</td>\n",
       "      <td>0.79926</td>\n",
       "      <td>0.81113</td>\n",
       "      <td>0.01122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF]</td>\n",
       "      <td>0.80192</td>\n",
       "      <td>0.78091</td>\n",
       "      <td>0.79965</td>\n",
       "      <td>0.81061</td>\n",
       "      <td>0.80253</td>\n",
       "      <td>0.81591</td>\n",
       "      <td>0.01199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.81195</td>\n",
       "      <td>0.79458</td>\n",
       "      <td>0.80778</td>\n",
       "      <td>0.81745</td>\n",
       "      <td>0.81205</td>\n",
       "      <td>0.82791</td>\n",
       "      <td>0.01099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.81462</td>\n",
       "      <td>0.79890</td>\n",
       "      <td>0.80505</td>\n",
       "      <td>0.82114</td>\n",
       "      <td>0.81670</td>\n",
       "      <td>0.83132</td>\n",
       "      <td>0.01153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.81705</td>\n",
       "      <td>0.80375</td>\n",
       "      <td>0.80607</td>\n",
       "      <td>0.82698</td>\n",
       "      <td>0.81986</td>\n",
       "      <td>0.82861</td>\n",
       "      <td>0.01037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.81666</td>\n",
       "      <td>0.80190</td>\n",
       "      <td>0.80609</td>\n",
       "      <td>0.82698</td>\n",
       "      <td>0.81968</td>\n",
       "      <td>0.82863</td>\n",
       "      <td>0.01085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.82197</td>\n",
       "      <td>0.80452</td>\n",
       "      <td>0.81075</td>\n",
       "      <td>0.83390</td>\n",
       "      <td>0.82715</td>\n",
       "      <td>0.83351</td>\n",
       "      <td>0.01210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.82745</td>\n",
       "      <td>0.81427</td>\n",
       "      <td>0.81581</td>\n",
       "      <td>0.83177</td>\n",
       "      <td>0.83181</td>\n",
       "      <td>0.84360</td>\n",
       "      <td>0.01102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.83663</td>\n",
       "      <td>0.82414</td>\n",
       "      <td>0.82672</td>\n",
       "      <td>0.84415</td>\n",
       "      <td>0.83595</td>\n",
       "      <td>0.85219</td>\n",
       "      <td>0.01052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84387</td>\n",
       "      <td>0.82871</td>\n",
       "      <td>0.83748</td>\n",
       "      <td>0.84947</td>\n",
       "      <td>0.84333</td>\n",
       "      <td>0.86033</td>\n",
       "      <td>0.01071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.84643</td>\n",
       "      <td>0.82943</td>\n",
       "      <td>0.84009</td>\n",
       "      <td>0.84985</td>\n",
       "      <td>0.84911</td>\n",
       "      <td>0.86365</td>\n",
       "      <td>0.01136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86044</td>\n",
       "      <td>0.84618</td>\n",
       "      <td>0.85328</td>\n",
       "      <td>0.86165</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.88107</td>\n",
       "      <td>0.01168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86066</td>\n",
       "      <td>0.84467</td>\n",
       "      <td>0.85402</td>\n",
       "      <td>0.86347</td>\n",
       "      <td>0.85942</td>\n",
       "      <td>0.88174</td>\n",
       "      <td>0.01228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86048</td>\n",
       "      <td>0.84457</td>\n",
       "      <td>0.85392</td>\n",
       "      <td>0.86282</td>\n",
       "      <td>0.85936</td>\n",
       "      <td>0.88174</td>\n",
       "      <td>0.01229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86049</td>\n",
       "      <td>0.84473</td>\n",
       "      <td>0.85360</td>\n",
       "      <td>0.86315</td>\n",
       "      <td>0.85924</td>\n",
       "      <td>0.88172</td>\n",
       "      <td>0.01229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86086</td>\n",
       "      <td>0.84452</td>\n",
       "      <td>0.85357</td>\n",
       "      <td>0.86404</td>\n",
       "      <td>0.86057</td>\n",
       "      <td>0.88158</td>\n",
       "      <td>0.01233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86458</td>\n",
       "      <td>0.84929</td>\n",
       "      <td>0.85037</td>\n",
       "      <td>0.86915</td>\n",
       "      <td>0.86746</td>\n",
       "      <td>0.88663</td>\n",
       "      <td>0.01379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86492</td>\n",
       "      <td>0.85023</td>\n",
       "      <td>0.85035</td>\n",
       "      <td>0.86749</td>\n",
       "      <td>0.86852</td>\n",
       "      <td>0.88802</td>\n",
       "      <td>0.01401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86475</td>\n",
       "      <td>0.85016</td>\n",
       "      <td>0.85017</td>\n",
       "      <td>0.86715</td>\n",
       "      <td>0.86824</td>\n",
       "      <td>0.88804</td>\n",
       "      <td>0.01404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86495</td>\n",
       "      <td>0.85038</td>\n",
       "      <td>0.85064</td>\n",
       "      <td>0.86834</td>\n",
       "      <td>0.86755</td>\n",
       "      <td>0.88786</td>\n",
       "      <td>0.01386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86561</td>\n",
       "      <td>0.85225</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>0.87010</td>\n",
       "      <td>0.86718</td>\n",
       "      <td>0.88715</td>\n",
       "      <td>0.01317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86620</td>\n",
       "      <td>0.85207</td>\n",
       "      <td>0.84943</td>\n",
       "      <td>0.87242</td>\n",
       "      <td>0.86860</td>\n",
       "      <td>0.88850</td>\n",
       "      <td>0.01430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86606</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>0.84943</td>\n",
       "      <td>0.87241</td>\n",
       "      <td>0.86860</td>\n",
       "      <td>0.88847</td>\n",
       "      <td>0.01443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86591</td>\n",
       "      <td>0.85137</td>\n",
       "      <td>0.84940</td>\n",
       "      <td>0.87218</td>\n",
       "      <td>0.86843</td>\n",
       "      <td>0.88816</td>\n",
       "      <td>0.01432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86591</td>\n",
       "      <td>0.85143</td>\n",
       "      <td>0.84922</td>\n",
       "      <td>0.87233</td>\n",
       "      <td>0.86834</td>\n",
       "      <td>0.88824</td>\n",
       "      <td>0.01438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86193</td>\n",
       "      <td>0.85143</td>\n",
       "      <td>0.83103</td>\n",
       "      <td>0.87095</td>\n",
       "      <td>0.86834</td>\n",
       "      <td>0.88791</td>\n",
       "      <td>0.01930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86283</td>\n",
       "      <td>0.85135</td>\n",
       "      <td>0.83580</td>\n",
       "      <td>0.87213</td>\n",
       "      <td>0.86807</td>\n",
       "      <td>0.88679</td>\n",
       "      <td>0.01761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86499</td>\n",
       "      <td>0.85081</td>\n",
       "      <td>0.84872</td>\n",
       "      <td>0.86901</td>\n",
       "      <td>0.86808</td>\n",
       "      <td>0.88831</td>\n",
       "      <td>0.01439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.85963</td>\n",
       "      <td>0.85076</td>\n",
       "      <td>0.82259</td>\n",
       "      <td>0.86829</td>\n",
       "      <td>0.86818</td>\n",
       "      <td>0.88831</td>\n",
       "      <td>0.02201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86557</td>\n",
       "      <td>0.85062</td>\n",
       "      <td>0.84842</td>\n",
       "      <td>0.87232</td>\n",
       "      <td>0.86818</td>\n",
       "      <td>0.88830</td>\n",
       "      <td>0.01474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86553</td>\n",
       "      <td>0.85058</td>\n",
       "      <td>0.84840</td>\n",
       "      <td>0.87216</td>\n",
       "      <td>0.86818</td>\n",
       "      <td>0.88830</td>\n",
       "      <td>0.01474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86556</td>\n",
       "      <td>0.85064</td>\n",
       "      <td>0.84842</td>\n",
       "      <td>0.87241</td>\n",
       "      <td>0.86818</td>\n",
       "      <td>0.88816</td>\n",
       "      <td>0.01470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86748</td>\n",
       "      <td>0.85284</td>\n",
       "      <td>0.85107</td>\n",
       "      <td>0.87360</td>\n",
       "      <td>0.87048</td>\n",
       "      <td>0.88942</td>\n",
       "      <td>0.01422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86729</td>\n",
       "      <td>0.85299</td>\n",
       "      <td>0.85097</td>\n",
       "      <td>0.87292</td>\n",
       "      <td>0.87015</td>\n",
       "      <td>0.88943</td>\n",
       "      <td>0.01415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.86842</td>\n",
       "      <td>0.85480</td>\n",
       "      <td>0.85252</td>\n",
       "      <td>0.87346</td>\n",
       "      <td>0.87124</td>\n",
       "      <td>0.89009</td>\n",
       "      <td>0.01372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...</td>\n",
       "      <td>0.87081</td>\n",
       "      <td>0.86059</td>\n",
       "      <td>0.85547</td>\n",
       "      <td>0.87383</td>\n",
       "      <td>0.87362</td>\n",
       "      <td>0.89054</td>\n",
       "      <td>0.01221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Features Used  Linear Regression R2  \\\n",
       "0                                       [OverallQual]               0.62823   \n",
       "1                            [OverallQual, GrLivArea]               0.74339   \n",
       "2               [OverallQual, GrLivArea, TotalBsmtSF]               0.80008   \n",
       "3     [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF]               0.80192   \n",
       "4   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.81195   \n",
       "5   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.81462   \n",
       "6   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.81705   \n",
       "7   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.81666   \n",
       "8   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.82197   \n",
       "9   [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.82745   \n",
       "10  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.83663   \n",
       "11  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84387   \n",
       "12  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.84643   \n",
       "13  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86044   \n",
       "14  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86066   \n",
       "15  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86048   \n",
       "16  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86049   \n",
       "17  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86086   \n",
       "18  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86458   \n",
       "19  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86492   \n",
       "20  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86475   \n",
       "21  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86495   \n",
       "22  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86561   \n",
       "23  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86620   \n",
       "24  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86606   \n",
       "25  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86591   \n",
       "26  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86591   \n",
       "27  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86193   \n",
       "28  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86283   \n",
       "29  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86499   \n",
       "30  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.85963   \n",
       "31  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86557   \n",
       "32  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86553   \n",
       "33  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86556   \n",
       "34  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86748   \n",
       "35  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86729   \n",
       "36  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.86842   \n",
       "37  [OverallQual, GrLivArea, TotalBsmtSF, 1stFlrSF...               0.87081   \n",
       "\n",
       "    Fold 1 R2  Fold 2 R2  Fold 3 R2  Fold 4 R2  Fold 5 R2  Standard Deviation  \n",
       "0     0.60518    0.62770    0.66175    0.61486    0.63167             0.01921  \n",
       "1     0.70856    0.74304    0.76797    0.73839    0.75898             0.02042  \n",
       "2     0.78189    0.79559    0.81254    0.79926    0.81113             0.01122  \n",
       "3     0.78091    0.79965    0.81061    0.80253    0.81591             0.01199  \n",
       "4     0.79458    0.80778    0.81745    0.81205    0.82791             0.01099  \n",
       "5     0.79890    0.80505    0.82114    0.81670    0.83132             0.01153  \n",
       "6     0.80375    0.80607    0.82698    0.81986    0.82861             0.01037  \n",
       "7     0.80190    0.80609    0.82698    0.81968    0.82863             0.01085  \n",
       "8     0.80452    0.81075    0.83390    0.82715    0.83351             0.01210  \n",
       "9     0.81427    0.81581    0.83177    0.83181    0.84360             0.01102  \n",
       "10    0.82414    0.82672    0.84415    0.83595    0.85219             0.01052  \n",
       "11    0.82871    0.83748    0.84947    0.84333    0.86033             0.01071  \n",
       "12    0.82943    0.84009    0.84985    0.84911    0.86365             0.01136  \n",
       "13    0.84618    0.85328    0.86165    0.86000    0.88107             0.01168  \n",
       "14    0.84467    0.85402    0.86347    0.85942    0.88174             0.01228  \n",
       "15    0.84457    0.85392    0.86282    0.85936    0.88174             0.01229  \n",
       "16    0.84473    0.85360    0.86315    0.85924    0.88172             0.01229  \n",
       "17    0.84452    0.85357    0.86404    0.86057    0.88158             0.01233  \n",
       "18    0.84929    0.85037    0.86915    0.86746    0.88663             0.01379  \n",
       "19    0.85023    0.85035    0.86749    0.86852    0.88802             0.01401  \n",
       "20    0.85016    0.85017    0.86715    0.86824    0.88804             0.01404  \n",
       "21    0.85038    0.85064    0.86834    0.86755    0.88786             0.01386  \n",
       "22    0.85225    0.85137    0.87010    0.86718    0.88715             0.01317  \n",
       "23    0.85207    0.84943    0.87242    0.86860    0.88850             0.01430  \n",
       "24    0.85137    0.84943    0.87241    0.86860    0.88847             0.01443  \n",
       "25    0.85137    0.84940    0.87218    0.86843    0.88816             0.01432  \n",
       "26    0.85143    0.84922    0.87233    0.86834    0.88824             0.01438  \n",
       "27    0.85143    0.83103    0.87095    0.86834    0.88791             0.01930  \n",
       "28    0.85135    0.83580    0.87213    0.86807    0.88679             0.01761  \n",
       "29    0.85081    0.84872    0.86901    0.86808    0.88831             0.01439  \n",
       "30    0.85076    0.82259    0.86829    0.86818    0.88831             0.02201  \n",
       "31    0.85062    0.84842    0.87232    0.86818    0.88830             0.01474  \n",
       "32    0.85058    0.84840    0.87216    0.86818    0.88830             0.01474  \n",
       "33    0.85064    0.84842    0.87241    0.86818    0.88816             0.01470  \n",
       "34    0.85284    0.85107    0.87360    0.87048    0.88942             0.01422  \n",
       "35    0.85299    0.85097    0.87292    0.87015    0.88943             0.01415  \n",
       "36    0.85480    0.85252    0.87346    0.87124    0.89009             0.01372  \n",
       "37    0.86059    0.85547    0.87383    0.87362    0.89054             0.01221  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KF_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8533ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plotting mean R2 score on the left y-axis\n",
    "ax1.plot(range(1, len(KF_results_df) + 1), KF_results_df['Linear Regression R2'], marker='o', label='Mean R2 Score', color='blue')\n",
    "ax1.set_xlabel('Number of Features')\n",
    "ax1.set_ylabel('Mean R-squared (R2) Score', color='blue')\n",
    "ax1.tick_params('y', colors='blue')\n",
    "\n",
    "# Create a secondary y-axis on the right side for standard deviation\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(range(1, len(KF_results_df) + 1), KF_results_df['Standard Deviation'], marker='o', label='Standard Deviation', color='red')\n",
    "ax2.set_ylabel('Standard Deviation', color='red')\n",
    "ax2.tick_params('y', colors='red')\n",
    "\n",
    "plt.title('Mean R-squared (R2) Score and Standard Deviation vs. Number of Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85163da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiscFeature\n",
       "Shed    88\n",
       "Gar2     5\n",
       "Othr     3\n",
       "TenC     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ames_HousePrice.loc[Ames_HousePrice.MiscFeature.notna()].MiscFeature.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5ab086f3-204e-488b-99d6-06c716a73bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 428952635.38812417\n",
      "R-squared: 0.9224454253475323\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is in the 'target_column' column\n",
    "target_column = 'SalePrice'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = housing_coords.drop(target_column, axis=1)\n",
    "y = housing_coords[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # You can customize the imputer strategy\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # You can customize the imputer strategy\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "    ])\n",
    "\n",
    "# Create a pipeline with preprocessor and the MLR model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', LinearRegression())])\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n",
    "print(f'R-squared: {r2_score(y_test, y_pred)}')\n",
    "\n",
    "# # Use 5-fold cross-validation\n",
    "# cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "# cv_scores_r2 = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "\n",
    "\n",
    "# # Convert the negative mean squared error to positive\n",
    "# cv_scores = -cv_scores\n",
    "\n",
    "# # Display cross-validation results\n",
    "# print(f'Cross-Validation Mean Squared Error: {cv_scores.mean()}')\n",
    "# print(f'Cross-Validation R-squared: {cv_scores_r2.mean()}')\n",
    "\n",
    "# for i, (mse, r2) in enumerate(zip(cv_scores, cv_scores_r2), 1):\n",
    "#     print(f'Fold {i}: Mean Squared Error = {mse}, R-squared = {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcf1af91-6f54-405e-9fdb-99d1ecbe6ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold R^2: 0.9038\n",
      "Fold R^2: 0.9190\n",
      "Fold R^2: 0.9162\n",
      "Fold R^2: 0.9160\n",
      "Fold R^2: 0.9276\n",
      "Average R^2: 0.9165\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is in the 'target_column' column\n",
    "target_column = 'SalePrice'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = housing_coords.drop(target_column, axis=1)\n",
    "y = housing_coords[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore')),])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features),])\n",
    "\n",
    "# Create a pipeline with preprocessor and the MLR model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),('regressor', LinearRegression())])\n",
    "\n",
    "r2_scorelist = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Create a Linear Regression model\n",
    "    # model = LinearRegression()\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared for this fold\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scorelist.append(r2)\n",
    "\n",
    "    print(f\"Fold R^2: {r2:.4f}\")\n",
    "    \n",
    "average_r2 = np.mean(r2_scorelist)\n",
    "print(f\"Average R^2: {average_r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d6306b3-bb3b-4a74-9912-8d79162deade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear Regression model\n",
      "Linear Regression - Fold 1 - R^2: 0.9038\n",
      "Linear Regression - Fold 2 - R^2: 0.9190\n",
      "Linear Regression - Fold 3 - R^2: 0.9162\n",
      "Linear Regression - Fold 4 - R^2: 0.9160\n",
      "Linear Regression - Fold 5 - R^2: 0.9276\n",
      "Linear Regression - Average R^2: 0.9165\n",
      "\n",
      "Training Lasso model\n",
      "Lasso - Fold 1 - R^2: 0.9032\n",
      "Lasso - Fold 2 - R^2: 0.9226\n",
      "Lasso - Fold 3 - R^2: 0.9227\n",
      "Lasso - Fold 4 - R^2: 0.9267\n",
      "Lasso - Fold 5 - R^2: 0.9327\n",
      "Lasso - Average R^2: 0.9216\n",
      "\n",
      "Training Ridge model\n",
      "Ridge - Fold 1 - R^2: 0.9130\n",
      "Ridge - Fold 2 - R^2: 0.9234\n",
      "Ridge - Fold 3 - R^2: 0.9262\n",
      "Ridge - Fold 4 - R^2: 0.9267\n",
      "Ridge - Fold 5 - R^2: 0.9361\n",
      "Ridge - Average R^2: 0.9251\n",
      "\n",
      "Training ElasticNet model\n",
      "ElasticNet - Fold 1 - R^2: 0.8718\n",
      "ElasticNet - Fold 2 - R^2: 0.8682\n",
      "ElasticNet - Fold 3 - R^2: 0.8904\n",
      "ElasticNet - Fold 4 - R^2: 0.8948\n",
      "ElasticNet - Fold 5 - R^2: 0.9134\n",
      "ElasticNet - Average R^2: 0.8877\n",
      "\n",
      "Overall Results:\n",
      "                Model  Fold   R2\n",
      "0   Linear Regression     1 0.90\n",
      "1   Linear Regression     2 0.92\n",
      "2   Linear Regression     3 0.92\n",
      "3   Linear Regression     4 0.92\n",
      "4   Linear Regression     5 0.93\n",
      "5               Lasso     1 0.90\n",
      "6               Lasso     2 0.92\n",
      "7               Lasso     3 0.92\n",
      "8               Lasso     4 0.93\n",
      "9               Lasso     5 0.93\n",
      "10              Ridge     1 0.91\n",
      "11              Ridge     2 0.92\n",
      "12              Ridge     3 0.93\n",
      "13              Ridge     4 0.93\n",
      "14              Ridge     5 0.94\n",
      "15         ElasticNet     1 0.87\n",
      "16         ElasticNet     2 0.87\n",
      "17         ElasticNet     3 0.89\n",
      "18         ElasticNet     4 0.89\n",
      "19         ElasticNet     5 0.91\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is in the 'SalePrice' column\n",
    "target_column = 'SalePrice'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = housing_coords.drop(target_column, axis=1)\n",
    "y = housing_coords[target_column]\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore')),])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features),])\n",
    "\n",
    "# Models to loop through\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet()\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model in models.items():\n",
    "    # print(f\"\\nTraining {model_name} model\")\n",
    "    \n",
    "    # Create a pipeline with preprocessor and the current model\n",
    "    full_model = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
    "    \n",
    "    r2_scorelist = []\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Loop over each fold\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Fit the model on the training data\n",
    "        full_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_pred = full_model.predict(X_test)\n",
    "        \n",
    "        # Calculate R-squared for this fold\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scorelist.append(r2)\n",
    "\n",
    "        # Append results to the list\n",
    "        results_list.append({'Model': model_name, 'Fold': fold, 'R2': r2})\n",
    "        \n",
    "        # print(f\"{model_name} - Fold {fold} - R^2: {r2:.4f}\")\n",
    "\n",
    "    # Calculate and print the average R-squared across folds for the current model\n",
    "    average_r2 = np.mean(r2_scorelist)\n",
    "    # print(f\"{model_name} - Average R^2: {average_r2:.4f}\")\n",
    "\n",
    "# Create the overall results DataFrame\n",
    "results_df_temp = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d4c3c22-7611-4204-8db5-ae737286078b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>mean_R2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.913032</td>\n",
       "      <td>0.923399</td>\n",
       "      <td>0.926178</td>\n",
       "      <td>0.926668</td>\n",
       "      <td>0.936059</td>\n",
       "      <td>0.925067</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.922622</td>\n",
       "      <td>0.922717</td>\n",
       "      <td>0.926668</td>\n",
       "      <td>0.932708</td>\n",
       "      <td>0.921580</td>\n",
       "      <td>0.009904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.903786</td>\n",
       "      <td>0.918992</td>\n",
       "      <td>0.916247</td>\n",
       "      <td>0.915996</td>\n",
       "      <td>0.927646</td>\n",
       "      <td>0.916533</td>\n",
       "      <td>0.007647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.868163</td>\n",
       "      <td>0.890415</td>\n",
       "      <td>0.894833</td>\n",
       "      <td>0.913406</td>\n",
       "      <td>0.887729</td>\n",
       "      <td>0.016448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Fold_1   Fold_2   Fold_3   Fold_4   Fold_5  mean_R2  \\\n",
       "Model                                                                     \n",
       "Ridge             0.913032 0.923399 0.926178 0.926668 0.936059 0.925067   \n",
       "Lasso             0.903185 0.922622 0.922717 0.926668 0.932708 0.921580   \n",
       "Linear Regression 0.903786 0.918992 0.916247 0.915996 0.927646 0.916533   \n",
       "ElasticNet        0.871826 0.868163 0.890415 0.894833 0.913406 0.887729   \n",
       "\n",
       "                       std  \n",
       "Model                       \n",
       "Ridge             0.007379  \n",
       "Lasso             0.009904  \n",
       "Linear Regression 0.007647  \n",
       "ElasticNet        0.016448  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = results_df_temp.pivot(index='Model', columns='Fold', values='R2').reset_index().set_index('Model')\n",
    "pivoted_df.columns = [f'Fold_{col}' if col != 'Model' else col for col in pivoted_df.columns]\n",
    "pivoted_df['mean_R2'] = pivoted_df.mean(axis=1)\n",
    "pivoted_df['std'] = pivoted_df.std(axis=1)\n",
    "pivoted_df.sort_values(by='mean_R2',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d029c40b-513b-46a1-9eac-c744910ffda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129f26e-9785-4def-849c-8f7ba654fbb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bb2d1-da3a-44a4-ba2b-31ececcd6332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cc2861a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█                                           | 1/42 [00:00<00:10,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8052803556009197, 'Adjusted R-Squared': 0.789229712461733, 'RMSE': 30200.381213329965, 'Time taken': 0.2572312355041504}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▎                                     | 6/42 [00:00<00:02, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8749524104774742, 'Adjusted R-Squared': 0.8646448000613007, 'RMSE': 24201.662672141763, 'Time taken': 0.2100679874420166}\n",
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8593062836631284, 'Adjusted R-Squared': 0.8477089708197421, 'RMSE': 25671.124432828645, 'Time taken': 0.042385101318359375}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7620351390730085, 'Adjusted R-Squared': 0.7424198143111307, 'RMSE': 33385.96678492327, 'Time taken': 0.04288601875305176}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.0011593988735663086, 'Adjusted R-Squared': -0.08368446862887113, 'RMSE': 68479.27528349646, 'Time taken': 0.006788015365600586}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.7849188004684498, 'Adjusted R-Squared': 0.767189764498387, 'RMSE': 31740.13474242726, 'Time taken': 0.009631156921386719}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.17804812903100742, 'Adjusted R-Squared': 0.1102950463914808, 'RMSE': 62048.42117041793, 'Time taken': 0.07125306129455566}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7082448836372934, 'Adjusted R-Squared': 0.6841956549566365, 'RMSE': 36967.21909952113, 'Time taken': 0.019160985946655273}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|█████████▍                                  | 9/42 [00:01<00:06,  5.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.8904178530153807, 'Adjusted R-Squared': 0.8813850513116593, 'RMSE': 22655.69783038078, 'Time taken': 0.9679830074310303}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': -2.72509326827243, 'Adjusted R-Squared': -3.0321508478697234, 'RMSE': 132091.87857015603, 'Time taken': 0.04563474655151367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████▎                               | 11/42 [00:01<00:05,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -5.221453418737638, 'Adjusted R-Squared': -5.7342847200652525, 'RMSE': 170707.84034065477, 'Time taken': 0.30130791664123535}\n",
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.8952481057756075, 'Adjusted R-Squared': 0.8866134593970242, 'RMSE': 22150.752453170993, 'Time taken': 0.7371320724487305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▍                          | 16/42 [00:03<00:06,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9092403065428093, 'Adjusted R-Squared': 0.9017590302925419, 'RMSE': 20618.356823813065, 'Time taken': 0.7182128429412842}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.5396810136197279, 'Adjusted R-Squared': 0.5017371492326338, 'RMSE': 46434.09496403739, 'Time taken': 0.030073881149291992}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.835497312158889, 'Adjusted R-Squared': 0.8219374376730707, 'RMSE': 27758.37511251118, 'Time taken': 0.0158841609954834}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -5.908644454284844, 'Adjusted R-Squared': -6.4781205698224245, 'RMSE': 179888.73281178036, 'Time taken': 0.09425783157348633}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8604694270500202, 'Adjusted R-Squared': 0.8489679915357051, 'RMSE': 25564.790017805597, 'Time taken': 0.012285232543945312}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8562220684974635, 'Adjusted R-Squared': 0.8443705253367338, 'RMSE': 25950.973651634355, 'Time taken': 0.02953505516052246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|███████████████████████▌                   | 23/42 [00:03<00:02,  9.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.8604700840573231, 'Adjusted R-Squared': 0.8489687026997922, 'RMSE': 25564.729829299395, 'Time taken': 0.0863640308380127}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8641909873138574, 'Adjusted R-Squared': 0.8529963181553466, 'RMSE': 25221.553734739027, 'Time taken': 0.0514678955078125}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.860492394337696, 'Adjusted R-Squared': 0.8489928520054453, 'RMSE': 25562.685898119675, 'Time taken': 0.009335756301879883}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8641390090414405, 'Adjusted R-Squared': 0.8529400553398672, 'RMSE': 25226.37980390595, 'Time taken': 0.028588056564331055}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8646751170547822, 'Adjusted R-Squared': 0.8535203544692761, 'RMSE': 25176.5589091963, 'Time taken': 0.018080949783325195}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8604093365226421, 'Adjusted R-Squared': 0.8489029477761353, 'RMSE': 25570.294318123633, 'Time taken': 0.015217065811157227}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -6.500219528178257, 'Adjusted R-Squared': -7.118458881910955, 'RMSE': 187432.34066626287, 'Time taken': 0.007720947265625}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 28/42 [00:05<00:02,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -6.240019178600884, 'Adjusted R-Squared': -6.836810347335881, 'RMSE': 184152.40686262806, 'Time taken': 0.9895749092102051}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.010115071811370946, 'Adjusted R-Squared': -0.09337835321881593, 'RMSE': 68784.87727059198, 'Time taken': 0.18944978713989258}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.7603513848941093, 'Adjusted R-Squared': 0.7405972691153156, 'RMSE': 33503.87216389746, 'Time taken': 0.00892019271850586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|█████████████████████████████████▊         | 33/42 [00:05<00:00,  9.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8085635069349029, 'Adjusted R-Squared': 0.7927834923221617, 'RMSE': 29944.695831932975, 'Time taken': 0.014944076538085938}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.3181305050791112, 'Adjusted R-Squared': 0.26192434280797494, 'RMSE': 56514.27648048477, 'Time taken': 0.06439590454101562}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': -0.9186436092332844, 'Adjusted R-Squared': -1.0767964447015381, 'RMSE': 94799.2053336583, 'Time taken': 0.0209348201751709}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': 0.42542391597239526, 'Adjusted R-Squared': 0.37806189603085727, 'RMSE': 51877.77170665488, 'Time taken': 0.09896492958068848}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████▊       | 35/42 [00:07<00:02,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.8844783710151564, 'Adjusted R-Squared': 0.8749559807734556, 'RMSE': 23261.579101550484, 'Time taken': 1.9360499382019043}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8604081741373707, 'Adjusted R-Squared': 0.848901689576026, 'RMSE': 25570.40078108786, 'Time taken': 0.008184194564819336}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.8598219275065135, 'Adjusted R-Squared': 0.8482671189278748, 'RMSE': 25624.03879010813, 'Time taken': 0.01689291000366211}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8296592555028424, 'Adjusted R-Squared': 0.8156181529195625, 'RMSE': 28246.641086410567, 'Time taken': 0.010668039321899414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:07<00:00,  4.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.062361933044770224, 'Adjusted R-Squared': -0.14993189715692057, 'RMSE': 70541.3539883291, 'Time taken': 0.30567479133605957}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8604093365226421, 'Adjusted R-Squared': 0.8489029477761353, 'RMSE': 25570.294318123633, 'Time taken': 0.015408039093017578}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.7517079680182288, 'Adjusted R-Squared': 0.7312413796986902, 'RMSE': 34102.713182886946, 'Time taken': 0.0155029296875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:07<00:00,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.8910177371713591, 'Adjusted R-Squared': 0.8820343836193236, 'RMSE': 22593.600830051637, 'Time taken': 0.33411192893981934}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4237\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 178817.771157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:08<00:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.9067960315056784, 'Adjusted R-Squared': 0.8991132748835868, 'RMSE': 20894.15168955877, 'Time taken': 0.6862080097198486}\n",
      "                               Adjusted R-Squared  R-Squared      RMSE  \\\n",
      "Model                                                                    \n",
      "HistGradientBoostingRegressor                0.90       0.91  20618.36   \n",
      "LGBMRegressor                                0.90       0.91  20894.15   \n",
      "GradientBoostingRegressor                    0.89       0.90  22150.75   \n",
      "XGBRegressor                                 0.88       0.89  22593.60   \n",
      "ExtraTreesRegressor                          0.88       0.89  22655.70   \n",
      "RandomForestRegressor                        0.87       0.88  23261.58   \n",
      "BaggingRegressor                             0.86       0.87  24201.66   \n",
      "LassoLarsIC                                  0.85       0.86  25176.56   \n",
      "LassoCV                                      0.85       0.86  25221.55   \n",
      "LassoLarsCV                                  0.85       0.86  25226.38   \n",
      "LassoLars                                    0.85       0.86  25562.69   \n",
      "Lasso                                        0.85       0.86  25564.73   \n",
      "Lars                                         0.85       0.86  25564.79   \n",
      "TransformedTargetRegressor                   0.85       0.86  25570.29   \n",
      "LinearRegression                             0.85       0.86  25570.29   \n",
      "Ridge                                        0.85       0.86  25570.40   \n",
      "RidgeCV                                      0.85       0.86  25624.04   \n",
      "BayesianRidge                                0.85       0.86  25671.12   \n",
      "LarsCV                                       0.84       0.86  25950.97   \n",
      "KNeighborsRegressor                          0.82       0.84  27758.38   \n",
      "SGDRegressor                                 0.82       0.83  28246.64   \n",
      "OrthogonalMatchingPursuitCV                  0.79       0.81  29944.70   \n",
      "AdaBoostRegressor                            0.79       0.81  30200.38   \n",
      "ElasticNet                                   0.77       0.78  31740.13   \n",
      "DecisionTreeRegressor                        0.74       0.76  33385.97   \n",
      "OrthogonalMatchingPursuit                    0.74       0.76  33503.87   \n",
      "TweedieRegressor                             0.73       0.75  34102.71   \n",
      "ExtraTreeRegressor                           0.68       0.71  36967.22   \n",
      "HuberRegressor                               0.50       0.54  46434.09   \n",
      "RANSACRegressor                              0.38       0.43  51877.77   \n",
      "PassiveAggressiveRegressor                   0.26       0.32  56514.28   \n",
      "ElasticNetCV                                 0.11       0.18  62048.42   \n",
      "DummyRegressor                              -0.08      -0.00  68479.28   \n",
      "NuSVR                                       -0.09      -0.01  68784.88   \n",
      "SVR                                         -0.15      -0.06  70541.35   \n",
      "PoissonRegressor                            -1.08      -0.92  94799.21   \n",
      "GammaRegressor                              -3.03      -2.73 132091.88   \n",
      "GaussianProcessRegressor                    -5.73      -5.22 170707.84   \n",
      "KernelRidge                                 -6.48      -5.91 179888.73   \n",
      "MLPRegressor                                -6.84      -6.24 184152.41   \n",
      "LinearSVR                                   -7.12      -6.50 187432.34   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "HistGradientBoostingRegressor        0.72  \n",
      "LGBMRegressor                        0.69  \n",
      "GradientBoostingRegressor            0.74  \n",
      "XGBRegressor                         0.33  \n",
      "ExtraTreesRegressor                  0.97  \n",
      "RandomForestRegressor                1.94  \n",
      "BaggingRegressor                     0.21  \n",
      "LassoLarsIC                          0.02  \n",
      "LassoCV                              0.05  \n",
      "LassoLarsCV                          0.03  \n",
      "LassoLars                            0.01  \n",
      "Lasso                                0.09  \n",
      "Lars                                 0.01  \n",
      "TransformedTargetRegressor           0.02  \n",
      "LinearRegression                     0.02  \n",
      "Ridge                                0.01  \n",
      "RidgeCV                              0.02  \n",
      "BayesianRidge                        0.04  \n",
      "LarsCV                               0.03  \n",
      "KNeighborsRegressor                  0.02  \n",
      "SGDRegressor                         0.01  \n",
      "OrthogonalMatchingPursuitCV          0.01  \n",
      "AdaBoostRegressor                    0.26  \n",
      "ElasticNet                           0.01  \n",
      "DecisionTreeRegressor                0.04  \n",
      "OrthogonalMatchingPursuit            0.01  \n",
      "TweedieRegressor                     0.02  \n",
      "ExtraTreeRegressor                   0.02  \n",
      "HuberRegressor                       0.03  \n",
      "RANSACRegressor                      0.10  \n",
      "PassiveAggressiveRegressor           0.06  \n",
      "ElasticNetCV                         0.07  \n",
      "DummyRegressor                       0.01  \n",
      "NuSVR                                0.19  \n",
      "SVR                                  0.31  \n",
      "PoissonRegressor                     0.02  \n",
      "GammaRegressor                       0.05  \n",
      "GaussianProcessRegressor             0.30  \n",
      "KernelRidge                          0.09  \n",
      "MLPRegressor                         0.99  \n",
      "LinearSVR                            0.01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "housing_num = housing_coords.select_dtypes(exclude=[object])\n",
    "features = list(housing_num.columns.values)\n",
    "features.remove('SalePrice')\n",
    "X = housing_coords[features]  # Features\n",
    "y = housing_coords['SalePrice']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% test\n",
    "\n",
    "reg = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n",
    "models, predictions = reg.fit(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c6fe8816-1ee3-4331-ae87-7336e6c0fb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:08,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.7994676724958087, 'Adjusted R-Squared': 0.7829378927883048, 'RMSE': 30647.830591890473, 'Time taken': 0.25650691986083984}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8704254205724764, 'Adjusted R-Squared': 0.8597446526370189, 'RMSE': 24635.84398235871, 'Time taken': 0.19007492065429688}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:02, 16.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8593062836631316, 'Adjusted R-Squared': 0.8477089708197454, 'RMSE': 25671.12443282837, 'Time taken': 0.015954017639160156}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7620351390730085, 'Adjusted R-Squared': 0.7424198143111307, 'RMSE': 33385.96678492327, 'Time taken': 0.035459041595458984}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.0011593988735663086, 'Adjusted R-Squared': -0.08368446862887113, 'RMSE': 68479.27528349646, 'Time taken': 0.005146980285644531}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.7849188004684501, 'Adjusted R-Squared': 0.7671897644983874, 'RMSE': 31740.134742427235, 'Time taken': 0.007748126983642578}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.1780481290310073, 'Adjusted R-Squared': 0.11029504639148069, 'RMSE': 62048.42117041794, 'Time taken': 0.04125213623046875}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7082448836372934, 'Adjusted R-Squared': 0.6841956549566365, 'RMSE': 36967.21909952113, 'Time taken': 0.018448829650878906}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:05,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.8904178530153807, 'Adjusted R-Squared': 0.8813850513116593, 'RMSE': 22655.69783038078, 'Time taken': 0.9099981784820557}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': -2.72509326827243, 'Adjusted R-Squared': -3.0321508478697234, 'RMSE': 132091.87857015603, 'Time taken': 0.010521173477172852}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -5.221453418737634, 'Adjusted R-Squared': -5.734284720065249, 'RMSE': 170707.84034065471, 'Time taken': 0.27967119216918945}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:02<00:07,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.8955444366071299, 'Adjusted R-Squared': 0.8869342166311449, 'RMSE': 22119.399322606772, 'Time taken': 0.6896226406097412}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▍                          | 16/42 [00:03<00:05,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9092403065428093, 'Adjusted R-Squared': 0.9017590302925419, 'RMSE': 20618.356823813065, 'Time taken': 0.48304009437561035}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.539681013621098, 'Adjusted R-Squared': 0.5017371492341169, 'RMSE': 46434.09496396828, 'Time taken': 0.03038167953491211}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.835497312158889, 'Adjusted R-Squared': 0.8219374376730707, 'RMSE': 27758.37511251118, 'Time taken': 0.015196800231933594}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -5.908644454285122, 'Adjusted R-Squared': -6.478120569822725, 'RMSE': 179888.73281178396, 'Time taken': 0.09666800498962402}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8604694270500197, 'Adjusted R-Squared': 0.8489679915357047, 'RMSE': 25564.790017805637, 'Time taken': 0.009563922882080078}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8646989616456069, 'Adjusted R-Squared': 0.8535461645578261, 'RMSE': 25174.34072441196, 'Time taken': 0.025063037872314453}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▌                  | 24/42 [00:03<00:01, 12.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.8604700840573231, 'Adjusted R-Squared': 0.8489687026997922, 'RMSE': 25564.729829299402, 'Time taken': 0.0882570743560791}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8647094145988505, 'Adjusted R-Squared': 0.8535574791427905, 'RMSE': 25173.368258522554, 'Time taken': 0.046488046646118164}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8604923943376963, 'Adjusted R-Squared': 0.8489928520054457, 'RMSE': 25562.685898119642, 'Time taken': 0.007876157760620117}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8646989616456069, 'Adjusted R-Squared': 0.8535461645578261, 'RMSE': 25174.34072441196, 'Time taken': 0.022449970245361328}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8646751170547817, 'Adjusted R-Squared': 0.8535203544692757, 'RMSE': 25176.558909196337, 'Time taken': 0.01640915870666504}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8513583902654562, 'Adjusted R-Squared': 0.8391059365346262, 'RMSE': 26386.254142395683, 'Time taken': 0.011219024658203125}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -6.500219528178257, 'Adjusted R-Squared': -7.118458881910955, 'RMSE': 187432.34066626287, 'Time taken': 0.007119178771972656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▋               | 27/42 [00:04<00:02,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -6.240816638256145, 'Adjusted R-Squared': -6.837673541192661, 'RMSE': 184162.5484152705, 'Time taken': 0.8580689430236816}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.010115071811370946, 'Adjusted R-Squared': -0.09337835321881593, 'RMSE': 68784.87727059198, 'Time taken': 0.18384575843811035}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.760351384894109, 'Adjusted R-Squared': 0.7405972691153153, 'RMSE': 33503.872163897475, 'Time taken': 0.006684064865112305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████▊          | 32/42 [00:04<00:01,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8085635069349028, 'Adjusted R-Squared': 0.7927834923221615, 'RMSE': 29944.695831932982, 'Time taken': 0.012547016143798828}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.31080876345845054, 'Adjusted R-Squared': 0.25399907367845287, 'RMSE': 56816.88429854626, 'Time taken': 0.06362700462341309}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': -0.9186436099855813, 'Adjusted R-Squared': -1.0767964455158463, 'RMSE': 94799.2053522436, 'Time taken': 0.01512002944946289}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': -3.23351185490679e+21, 'Adjusted R-Squared': -3.5000486238578923e+21, 'RMSE': 3891748528538462.5, 'Time taken': 0.09686970710754395}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|███████████████████████████████████▊       | 35/42 [00:06<00:01,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.8852965822575252, 'Adjusted R-Squared': 0.8758416367603147, 'RMSE': 23179.05469943771, 'Time taken': 1.841257095336914}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8604081741373715, 'Adjusted R-Squared': 0.8489016895760269, 'RMSE': 25570.40078108779, 'Time taken': 0.008296966552734375}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.859821927506477, 'Adjusted R-Squared': 0.8482671189278352, 'RMSE': 25624.03879011146, 'Time taken': 0.01815199851989746}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8444441590337946, 'Adjusted R-Squared': 0.831621768672155, 'RMSE': 26992.9719041132, 'Time taken': 0.008022785186767578}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:06<00:00,  4.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.062361933044770224, 'Adjusted R-Squared': -0.14993189715692057, 'RMSE': 70541.3539883291, 'Time taken': 0.29565906524658203}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8513583902654562, 'Adjusted R-Squared': 0.8391059365346262, 'RMSE': 26386.254142395683, 'Time taken': 0.012755870819091797}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.7517079680098993, 'Adjusted R-Squared': 0.731241379689674, 'RMSE': 34102.71318345897, 'Time taken': 0.012140035629272461}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:07<00:00,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.8910177371713591, 'Adjusted R-Squared': 0.8820343836193236, 'RMSE': 22593.600830051637, 'Time taken': 0.28450465202331543}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4237\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 178817.771157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:07<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.9067960315056784, 'Adjusted R-Squared': 0.8991132748835868, 'RMSE': 20894.15168955877, 'Time taken': 0.290477991104126}\n",
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Regressor(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:08,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8457441565882792, 'Adjusted R-Squared': 0.833028924376467, 'RMSE': 30970.555828886427, 'Time taken': 0.24102520942687988}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8733416489171791, 'Adjusted R-Squared': 0.8629012642292242, 'RMSE': 28063.711190409584, 'Time taken': 0.18559503555297852}\n",
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8552859827454197, 'Adjusted R-Squared': 0.8433572785031767, 'RMSE': 29997.391227586766, 'Time taken': 0.013746023178100586}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:01, 17.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7528648146077457, 'Adjusted R-Squared': 0.7324935845754124, 'RMSE': 39200.849475311115, 'Time taken': 0.035485029220581055}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.002218814892503973, 'Adjusted R-Squared': -0.08483121178169095, 'RMSE': 78942.24322965916, 'Time taken': 0.0052242279052734375}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.8341504412947542, 'Adjusted R-Squared': 0.82047954491558, 'RMSE': 32113.330395383993, 'Time taken': 0.007275819778442383}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.16304751563711783, 'Adjusted R-Squared': 0.09405793991957001, 'RMSE': 72140.40710366426, 'Time taken': 0.04080629348754883}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7869425786957719, 'Adjusted R-Squared': 0.7693803617552932, 'RMSE': 36397.91618134203, 'Time taken': 0.01760101318359375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:05,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.9050666215713369, 'Adjusted R-Squared': 0.8972413105511867, 'RMSE': 24296.16093620211, 'Time taken': 0.9603941440582275}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.8726572746418026, 'Adjusted R-Squared': 0.8621604773237733, 'RMSE': 28139.427507577155, 'Time taken': 0.011311769485473633}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -4.111571060215291, 'Adjusted R-Squared': -4.532915312467312, 'RMSE': 178281.1343531313, 'Time taken': 0.24654579162597656}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:02<00:07,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.9154596552481793, 'Adjusted R-Squared': 0.9084910368087667, 'RMSE': 22927.68438039806, 'Time taken': 0.6858208179473877}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▍                         | 17/42 [00:03<00:04,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.8981341650992072, 'Adjusted R-Squared': 0.8897374151507688, 'RMSE': 25167.63819031748, 'Time taken': 0.48851799964904785}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.8372796480396345, 'Adjusted R-Squared': 0.8238666906112313, 'RMSE': 31808.934721113, 'Time taken': 0.0229489803314209}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.8246270034078034, 'Adjusted R-Squared': 0.8101710947949976, 'RMSE': 33022.46958086206, 'Time taken': 0.01168680191040039}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -4.205457755411456, 'Adjusted R-Squared': -4.634541041106978, 'RMSE': 179910.97226506466, 'Time taken': 0.08123278617858887}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8542176114442329, 'Adjusted R-Squared': 0.84220084188866, 'RMSE': 30107.917559088277, 'Time taken': 0.009545087814331055}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8560909383170213, 'Adjusted R-Squared': 0.8442285861609407, 'RMSE': 29913.846317699932, 'Time taken': 0.025928974151611328}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▌                  | 24/42 [00:03<00:01, 12.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.8554804068899248, 'Adjusted R-Squared': 0.843567728932912, 'RMSE': 29977.233617912487, 'Time taken': 0.07649517059326172}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8562436329255898, 'Adjusted R-Squared': 0.8443938673099117, 'RMSE': 29897.972072957185, 'Time taken': 0.04796314239501953}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8554748446284148, 'Adjusted R-Squared': 0.843561708176961, 'RMSE': 29977.81049335473, 'Time taken': 0.008335113525390625}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8562413121518346, 'Adjusted R-Squared': 0.8443913552359338, 'RMSE': 29898.213405394465, 'Time taken': 0.02456188201904297}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8562370009737328, 'Adjusted R-Squared': 0.8443866886895719, 'RMSE': 29898.66171067081, 'Time taken': 0.015497922897338867}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8554688009152305, 'Adjusted R-Squared': 0.8435551662835141, 'RMSE': 29978.437288717745, 'Time taken': 0.012166023254394531}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -5.171590998037044, 'Adjusted R-Squared': -5.680312164903439, 'RMSE': 195896.53569262, 'Time taken': 0.006873130798339844}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▋               | 27/42 [00:04<00:02,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -4.943064970924351, 'Adjusted R-Squared': -5.432948851391001, 'RMSE': 192235.42688646846, 'Time taken': 0.8217790126800537}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.021449712354327577, 'Adjusted R-Squared': -0.10564730252670174, 'RMSE': 79696.02903635043, 'Time taken': 0.1843550205230713}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.8126724998898105, 'Adjusted R-Squared': 0.7972311875163025, 'RMSE': 34129.42379170525, 'Time taken': 0.006821155548095703}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▋           | 31/42 [00:04<00:01,  9.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8315315281721478, 'Adjusted R-Squared': 0.8176447560908932, 'RMSE': 32365.88640836856, 'Time taken': 0.013441085815429688}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.832039543133377, 'Adjusted R-Squared': 0.8181946464719201, 'RMSE': 32317.050063760616, 'Time taken': 0.06747984886169434}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.9078943852900365, 'Adjusted R-Squared': 0.9003021654224039, 'RMSE': 23931.572710523287, 'Time taken': 0.018790006637573242}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': 0.7040469256280567, 'Adjusted R-Squared': 0.6796516613631243, 'RMSE': 42898.25389554795, 'Time taken': 0.08708405494689941}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▊        | 34/42 [00:06<00:02,  3.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.8916592496498548, 'Adjusted R-Squared': 0.8827287756513612, 'RMSE': 25955.183697698343, 'Time taken': 1.7988831996917725}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8554551608420287, 'Adjusted R-Squared': 0.8435404018658835, 'RMSE': 29979.851856764315, 'Time taken': 0.006577014923095703}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.855366289958318, 'Adjusted R-Squared': 0.8434442053995677, 'RMSE': 29989.06673617207, 'Time taken': 0.01343536376953125}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.856076094844267, 'Adjusted R-Squared': 0.8442125191481329, 'RMSE': 29915.38900691096, 'Time taken': 0.0069239139556884766}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:06<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.07126083439906794, 'Adjusted R-Squared': -0.15956433051005403, 'RMSE': 81616.0929934135, 'Time taken': 0.3015778064727783}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8554688009152305, 'Adjusted R-Squared': 0.8435551662835141, 'RMSE': 29978.437288717745, 'Time taken': 0.012137889862060547}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.8136830509667172, 'Adjusted R-Squared': 0.7983250378142991, 'RMSE': 34037.24254265621, 'Time taken': 0.010024070739746094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:06<00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.8972606896434427, 'Adjusted R-Squared': 0.888791939548976, 'RMSE': 25275.311139730344, 'Time taken': 0.2913980484008789}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4234\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 177607.365548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:07<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.8984177187941947, 'Adjusted R-Squared': 0.8900443420353648, 'RMSE': 25132.58546661574, 'Time taken': 0.2873978614807129}\n",
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Regressor(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:08,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8225667569896494, 'Adjusted R-Squared': 0.8079092282192292, 'RMSE': 32669.561647223203, 'Time taken': 0.250730037689209}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.8800711098837766, 'Adjusted R-Squared': 0.8701639407002625, 'RMSE': 26858.86889526075, 'Time taken': 0.1876230239868164}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:02, 17.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8740668284718082, 'Adjusted R-Squared': 0.8636636534325228, 'RMSE': 27523.007120877224, 'Time taken': 0.014148950576782227}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7503857577318132, 'Adjusted R-Squared': 0.7297654507618325, 'RMSE': 38748.99943056259, 'Time taken': 0.03610587120056152}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.00031085276618503244, 'Adjusted R-Squared': -0.0829452275599134, 'RMSE': 77569.9126500137, 'Time taken': 0.005067110061645508}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.857639646541541, 'Adjusted R-Squared': 0.8458794434297553, 'RMSE': 29263.10063735466, 'Time taken': 0.010174989700317383}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.16958924202096226, 'Adjusted R-Squared': 0.10099009244878088, 'RMSE': 70676.05425790342, 'Time taken': 0.03945660591125488}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7467900271198753, 'Adjusted R-Squared': 0.7258726815341259, 'RMSE': 39027.09408802956, 'Time taken': 0.017611980438232422}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:05,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.9121711102507346, 'Adjusted R-Squared': 0.9049156802279692, 'RMSE': 22985.000021018514, 'Time taken': 0.9055337905883789}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.8974276226037098, 'Adjusted R-Squared': 0.8889542522970597, 'RMSE': 24839.395521023413, 'Time taken': 0.010448932647705078}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -4.0305183310593895, 'Adjusted R-Squared': -4.4460828888425565, 'RMSE': 173953.10294036788, 'Time taken': 0.2725701332092285}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:02<00:07,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.9177722458566225, 'Adjusted R-Squared': 0.9109795183404304, 'RMSE': 22240.01246950312, 'Time taken': 0.6864781379699707}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▍                        | 18/42 [00:02<00:03,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9057311293923686, 'Adjusted R-Squared': 0.8979437009508686, 'RMSE': 23812.772566144184, 'Time taken': 0.3766319751739502}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.863702754954309, 'Adjusted R-Squared': 0.8524434173200998, 'RMSE': 28633.16466667431, 'Time taken': 0.022559165954589844}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.841276964340222, 'Adjusted R-Squared': 0.8281650613944143, 'RMSE': 30899.097344286667, 'Time taken': 0.01203608512878418}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -4.41550367248632, 'Adjusted R-Squared': -4.862871367169973, 'RMSE': 180486.71454051483, 'Time taken': 0.07471585273742676}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8732710635219141, 'Adjusted R-Squared': 0.8628021513780721, 'RMSE': 27609.82838432063, 'Time taken': 0.008461236953735352}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8292972115681325, 'Adjusted R-Squared': 0.8151956768715869, 'RMSE': 32043.95548515371, 'Time taken': 0.022868871688842773}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▍                      | 20/42 [00:03<00:02,  8.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.8739665879163082, 'Adjusted R-Squared': 0.8635551321354815, 'RMSE': 27533.958853032782, 'Time taken': 0.07738590240478516}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8743782416122443, 'Adjusted R-Squared': 0.8640007920062993, 'RMSE': 27488.955999783528, 'Time taken': 0.04726099967956543}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8739653559851173, 'Adjusted R-Squared': 0.8635537984360617, 'RMSE': 27534.093419967343, 'Time taken': 0.008720874786376953}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8743750992885324, 'Adjusted R-Squared': 0.8639973900993242, 'RMSE': 27489.29980430908, 'Time taken': 0.025244951248168945}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8743770243036209, 'Adjusted R-Squared': 0.8639994741373982, 'RMSE': 27489.089187149126, 'Time taken': 0.01679682731628418}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.873945066864791, 'Adjusted R-Squared': 0.8635318332579693, 'RMSE': 27536.309556879576, 'Time taken': 0.01180124282836914}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -5.106330673794821, 'Adjusted R-Squared': -5.610766685977871, 'RMSE': 191653.1543097577, 'Time taken': 0.006109952926635742}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 28/42 [00:04<00:01,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -4.871337789618438, 'Adjusted R-Squared': -5.356361346152134, 'RMSE': 187929.23484005165, 'Time taken': 0.8527460098266602}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.005113446076259853, 'Adjusted R-Squared': -0.08814455683908129, 'RMSE': 77755.9001688403, 'Time taken': 0.18668007850646973}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.792701178230012, 'Adjusted R-Squared': 0.7755764929533608, 'RMSE': 35312.155551526994, 'Time taken': 0.005921125411987305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▋           | 31/42 [00:04<00:01,  9.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8253728027666702, 'Adjusted R-Squared': 0.8109470777778299, 'RMSE': 32410.20319795896, 'Time taken': 0.01354217529296875}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.8619006635995609, 'Adjusted R-Squared': 0.8504924575490898, 'RMSE': 28821.83369411896, 'Time taken': 0.06934499740600586}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.9375657153254576, 'Adjusted R-Squared': 0.9324081005045172, 'RMSE': 19379.268601508666, 'Time taken': 0.019939184188842773}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': -1.6273121804977443e+23, 'Adjusted R-Squared': -1.761742317147558e+23, 'RMSE': 3.1286807468661396e+16, 'Time taken': 0.09412622451782227}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▊        | 34/42 [00:06<00:02,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.892645231640483, 'Adjusted R-Squared': 0.883776794254262, 'RMSE': 25411.86161607652, 'Time taken': 1.8111696243286133}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8739675410007057, 'Adjusted R-Squared': 0.8635561639529379, 'RMSE': 27533.85474478179, 'Time taken': 0.008125066757202148}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.8740357505805008, 'Adjusted R-Squared': 0.8636300082371509, 'RMSE': 27526.402986511595, 'Time taken': 0.012862205505371094}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8701013117246013, 'Adjusted R-Squared': 0.8593705505192423, 'RMSE': 27952.985217565056, 'Time taken': 0.011443853378295898}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:06<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.04732889164840337, 'Adjusted R-Squared': -0.13384736530631502, 'RMSE': 79372.00556188852, 'Time taken': 0.3017301559448242}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.873945066864791, 'Adjusted R-Squared': 0.8635318332579693, 'RMSE': 27536.309556879576, 'Time taken': 0.013353109359741211}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.8391004038240746, 'Adjusted R-Squared': 0.8258086980530199, 'RMSE': 31110.234815975135, 'Time taken': 0.010383844375610352}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:06<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.9137808950288178, 'Adjusted R-Squared': 0.9066584472268505, 'RMSE': 22773.383893445847, 'Time taken': 0.29545092582702637}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4232\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 178624.403904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:07<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.8990304095606648, 'Adjusted R-Squared': 0.8906894433939372, 'RMSE': 24644.562306642416, 'Time taken': 0.36384105682373047}\n",
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Regressor(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:08,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8379402155223017, 'Adjusted R-Squared': 0.8245526681089266, 'RMSE': 30064.118755898136, 'Time taken': 0.24839401245117188}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.9116225993122224, 'Adjusted R-Squared': 0.9043218575162756, 'RMSE': 22201.456248638297, 'Time taken': 0.191741943359375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:02, 17.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8739175002364419, 'Adjusted R-Squared': 0.8635019893864089, 'RMSE': 26517.84666973283, 'Time taken': 0.014555931091308594}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.7932648451482421, 'Adjusted R-Squared': 0.7761867236604882, 'RMSE': 33956.11663154947, 'Time taken': 0.03590703010559082}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.0004607825108622343, 'Adjusted R-Squared': -0.08310754280523769, 'RMSE': 74698.32858680877, 'Time taken': 0.0051839351654052734}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.8579110408166435, 'Adjusted R-Squared': 0.8461732572319314, 'RMSE': 28150.81782276287, 'Time taken': 0.007635831832885742}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.1683022917459721, 'Adjusted R-Squared': 0.0995968288902046, 'RMSE': 68107.29034051187, 'Time taken': 0.03975701332092285}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.783343660868699, 'Adjusted R-Squared': 0.7654459632882872, 'RMSE': 34761.343241622926, 'Time taken': 0.017494916915893555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:05,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.9250011547785004, 'Adjusted R-Squared': 0.918805597999333, 'RMSE': 20452.110853501166, 'Time taken': 0.9037868976593018}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.8812700039532124, 'Adjusted R-Squared': 0.8714618738449995, 'RMSE': 25733.038894857178, 'Time taken': 0.009286880493164062}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -4.455707150885561, 'Adjusted R-Squared': -4.906396002480455, 'RMSE': 174436.10269071956, 'Time taken': 0.23140788078308105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:02<00:07,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.9315825072415792, 'Adjusted R-Squared': 0.925930627405014, 'RMSE': 19534.145903475048, 'Time taken': 0.686945915222168}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▍                         | 17/42 [00:02<00:03,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9176435344623108, 'Adjusted R-Squared': 0.9108401742657192, 'RMSE': 21431.85190919207, 'Time taken': 0.35915613174438477}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.864448290667075, 'Adjusted R-Squared': 0.8532505407656594, 'RMSE': 27495.609360407965, 'Time taken': 0.027704238891601562}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.8706031831937979, 'Adjusted R-Squared': 0.8599138809358943, 'RMSE': 26864.121692099594, 'Time taken': 0.013562202453613281}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -4.8197580818342844, 'Adjusted R-Squared': -5.300520705985812, 'RMSE': 180162.0503817141, 'Time taken': 0.0824441909790039}\n",
      "{'Model': 'Lars', 'R-Squared': 0.8736181487593818, 'Adjusted R-Squared': 0.8631779088742872, 'RMSE': 26549.308015976178, 'Time taken': 0.008423089981079102}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8454198196571828, 'Adjusted R-Squared': 0.8326501525853849, 'RMSE': 29362.143347100315, 'Time taken': 0.026015043258666992}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|████████████████████████▌                  | 24/42 [00:03<00:01, 12.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.8736181650868668, 'Adjusted R-Squared': 0.8631779265505646, 'RMSE': 26549.30630100112, 'Time taken': 0.09120488166809082}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8725533883458318, 'Adjusted R-Squared': 0.8620251899917919, 'RMSE': 26660.911703255788, 'Time taken': 0.045237064361572266}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8736218600343522, 'Adjusted R-Squared': 0.8631819267328421, 'RMSE': 26548.918195346385, 'Time taken': 0.0078008174896240234}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8726104706096842, 'Adjusted R-Squared': 0.862086987747006, 'RMSE': 26654.94043566985, 'Time taken': 0.022871971130371094}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.873848261862352, 'Adjusted R-Squared': 0.8634270313205463, 'RMSE': 26525.126825950865, 'Time taken': 0.016768217086791992}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8735994613990344, 'Adjusted R-Squared': 0.8631576777754764, 'RMSE': 26551.27079046531, 'Time taken': 0.011958122253417969}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -5.657696335272507, 'Adjusted R-Squared': -6.2076799455776275, 'RMSE': 192696.06275975698, 'Time taken': 0.0068700313568115234}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▋               | 27/42 [00:04<00:02,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -5.411782900414239, 'Adjusted R-Squared': -5.941451922622371, 'RMSE': 189103.79923629467, 'Time taken': 0.9559140205383301}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.015207817116165145, 'Adjusted R-Squared': -0.09907281070402219, 'RMSE': 75246.85038613736, 'Time taken': 0.18239188194274902}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.7899064852833659, 'Adjusted R-Squared': 0.772550934067644, 'RMSE': 34230.809772951245, 'Time taken': 0.006448984146118164}\n",
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8295616602760703, 'Adjusted R-Squared': 0.8154819713423543, 'RMSE': 30831.488848460307, 'Time taken': 0.011832952499389648}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▋           | 31/42 [00:04<00:01,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.8638080176652061, 'Adjusted R-Squared': 0.8525573756462449, 'RMSE': 27560.47005680055, 'Time taken': 0.07501411437988281}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.9230391284022651, 'Adjusted R-Squared': 0.9166814911833218, 'RMSE': 20717.905057381835, 'Time taken': 0.022622108459472656}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': -5.8399240407814205e+22, 'Adjusted R-Squared': -6.3223525484981465e+22, 'RMSE': 1.8047391890066692e+16, 'Time taken': 0.0933687686920166}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▊        | 34/42 [00:06<00:02,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.9141213583209508, 'Adjusted R-Squared': 0.9070270357474641, 'RMSE': 21885.346808802005, 'Time taken': 1.8778541088104248}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8736401041273023, 'Adjusted R-Squared': 0.8632016779465143, 'RMSE': 26547.001810070415, 'Time taken': 0.007584095001220703}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.8738133154451397, 'Adjusted R-Squared': 0.8633891980253904, 'RMSE': 26528.80055242902, 'Time taken': 0.016301870346069336}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8705941485656755, 'Adjusted R-Squared': 0.8599040999689269, 'RMSE': 26865.05951699721, 'Time taken': 0.007598161697387695}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:06<00:00,  4.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.0674135706770187, 'Adjusted R-Squared': -0.15559121347207672, 'RMSE': 77157.33339285305, 'Time taken': 0.2995939254760742}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8735994613990344, 'Adjusted R-Squared': 0.8631576777754764, 'RMSE': 26551.27079046531, 'Time taken': 0.014475107192993164}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.8380891260425444, 'Adjusted R-Squared': 0.8247138799330154, 'RMSE': 30050.30319870634, 'Time taken': 0.013542890548706055}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:07<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.9009848136855478, 'Adjusted R-Squared': 0.892805298294354, 'RMSE': 23499.669493376907, 'Time taken': 0.30597519874572754}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4227\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 178030.776276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:07<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.9211742440237395, 'Adjusted R-Squared': 0.9146625511387441, 'RMSE': 20967.41649279922, 'Time taken': 0.31432580947875977}\n",
      "'tuple' object has no attribute '__name__'\n",
      "Invalid Regressor(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|██                                          | 2/42 [00:00<00:08,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'AdaBoostRegressor', 'R-Squared': 0.8530707630605383, 'Adjusted R-Squared': 0.8409331304438001, 'RMSE': 28864.96591566282, 'Time taken': 0.24951982498168945}\n",
      "{'Model': 'BaggingRegressor', 'R-Squared': 0.9193657467264358, 'Adjusted R-Squared': 0.9127046562386196, 'RMSE': 21383.398113183364, 'Time taken': 0.19934296607971191}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▎                                    | 7/42 [00:00<00:02, 16.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'BayesianRidge', 'R-Squared': 0.8906751664193001, 'Adjusted R-Squared': 0.8816439845148075, 'RMSE': 24898.681505035544, 'Time taken': 0.015605926513671875}\n",
      "{'Model': 'DecisionTreeRegressor', 'R-Squared': 0.8173242672509039, 'Adjusted R-Squared': 0.8022336632411959, 'RMSE': 32185.285542572306, 'Time taken': 0.03599882125854492}\n",
      "{'Model': 'DummyRegressor', 'R-Squared': -0.00046382304924130757, 'Adjusted R-Squared': -0.08311083451852652, 'RMSE': 75321.26963452704, 'Time taken': 0.005290985107421875}\n",
      "{'Model': 'ElasticNet', 'R-Squared': 0.8757302338002599, 'Adjusted R-Squared': 0.8654644705054988, 'RMSE': 26546.035941875092, 'Time taken': 0.007762908935546875}\n",
      "{'Model': 'ElasticNetCV', 'R-Squared': 0.17389745865103357, 'Adjusted R-Squared': 0.10565420523524938, 'RMSE': 68443.76894777843, 'Time taken': 0.04133009910583496}\n",
      "{'Model': 'ExtraTreeRegressor', 'R-Squared': 0.7859995422212148, 'Adjusted R-Squared': 0.7683212435351413, 'RMSE': 34835.6796911599, 'Time taken': 0.0188448429107666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▏                                | 10/42 [00:01<00:05,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'ExtraTreesRegressor', 'R-Squared': 0.9345043345643663, 'Adjusted R-Squared': 0.9290938230718575, 'RMSE': 19271.841576566498, 'Time taken': 0.9047770500183105}\n",
      "{'Model': 'GammaRegressor', 'R-Squared': 0.8940538352311648, 'Adjusted R-Squared': 0.885301760750261, 'RMSE': 24510.916891537596, 'Time taken': 0.009308815002441406}\n",
      "{'Model': 'GaussianProcessRegressor', 'R-Squared': -4.256874321242808, 'Adjusted R-Squared': -4.691137852128083, 'RMSE': 172655.62604729852, 'Time taken': 0.2306380271911621}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|████████████▎                              | 12/42 [00:02<00:07,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'GradientBoostingRegressor', 'R-Squared': 0.9438027129403113, 'Adjusted R-Squared': 0.9391603283571196, 'RMSE': 17851.495823031175, 'Time taken': 0.6840348243713379}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|██████████████████▍                        | 18/42 [00:02<00:03,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'HistGradientBoostingRegressor', 'R-Squared': 0.9442886491093456, 'Adjusted R-Squared': 0.9396864070792481, 'RMSE': 17774.147592354675, 'Time taken': 0.3883209228515625}\n",
      "{'Model': 'HuberRegressor', 'R-Squared': 0.8816554467240629, 'Adjusted R-Squared': 0.8718791575403986, 'RMSE': 25905.446062924948, 'Time taken': 0.03320503234863281}\n",
      "{'Model': 'KNeighborsRegressor', 'R-Squared': 0.8648862304564245, 'Adjusted R-Squared': 0.8537246581897814, 'RMSE': 27680.041869752702, 'Time taken': 0.011085033416748047}\n",
      "{'Model': 'KernelRidge', 'R-Squared': -4.780539105206276, 'Adjusted R-Squared': -5.25806190085375, 'RMSE': 181051.07558176748, 'Time taken': 0.07571816444396973}\n",
      "{'Model': 'Lars', 'R-Squared': 0.890547479482199, 'Adjusted R-Squared': 0.8815057495263807, 'RMSE': 24913.217583035006, 'Time taken': 0.008175849914550781}\n",
      "{'Model': 'LarsCV', 'R-Squared': 0.8534889015408423, 'Adjusted R-Squared': 0.8413858107985641, 'RMSE': 28823.863979429476, 'Time taken': 0.023509979248046875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▍                      | 20/42 [00:03<00:02,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'Lasso', 'R-Squared': 0.890551706804692, 'Adjusted R-Squared': 0.8815103260624709, 'RMSE': 24912.736473867873, 'Time taken': 0.09720683097839355}\n",
      "{'Model': 'LassoCV', 'R-Squared': 0.8906529768102842, 'Adjusted R-Squared': 0.8816199618511338, 'RMSE': 24901.208213549966, 'Time taken': 0.046656131744384766}\n",
      "{'Model': 'LassoLars', 'R-Squared': 0.8905496568649859, 'Adjusted R-Squared': 0.8815081067799195, 'RMSE': 24912.969777499507, 'Time taken': 0.00868988037109375}\n",
      "{'Model': 'LassoLarsCV', 'R-Squared': 0.8906466914352615, 'Adjusted R-Squared': 0.8816131572494788, 'RMSE': 24901.923876301924, 'Time taken': 0.025293827056884766}\n",
      "{'Model': 'LassoLarsIC', 'R-Squared': 0.8906190502351554, 'Adjusted R-Squared': 0.8815832326458857, 'RMSE': 24905.070903030602, 'Time taken': 0.015084981918334961}\n",
      "{'Model': 'LinearRegression', 'R-Squared': 0.8905527933675629, 'Adjusted R-Squared': 0.8815115023848833, 'RMSE': 24912.61281126493, 'Time taken': 0.012749910354614258}\n",
      "{'Model': 'LinearSVR', 'R-Squared': -5.4040256534172215, 'Adjusted R-Squared': -5.933053859569079, 'RMSE': 190565.14467595253, 'Time taken': 0.006181955337524414}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|████████████████████████████▋              | 28/42 [00:04<00:01,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'MLPRegressor', 'R-Squared': -5.160532745729985, 'Adjusted R-Squared': -5.6694463203772445, 'RMSE': 186907.21769728285, 'Time taken': 0.8178732395172119}\n",
      "{'Model': 'NuSVR', 'R-Squared': -0.009150018285263295, 'Adjusted R-Squared': -0.09251458501317633, 'RMSE': 75647.53895149643, 'Time taken': 0.18813300132751465}\n",
      "{'Model': 'OrthogonalMatchingPursuit', 'R-Squared': 0.8118985919571317, 'Adjusted R-Squared': 0.796359779988373, 'RMSE': 32659.75787069087, 'Time taken': 0.006396293640136719}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▋           | 31/42 [00:04<00:01,  9.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'OrthogonalMatchingPursuitCV', 'R-Squared': 0.8631876547689956, 'Adjusted R-Squared': 0.8518857653803474, 'RMSE': 27853.487555804844, 'Time taken': 0.013304948806762695}\n",
      "{'Model': 'PassiveAggressiveRegressor', 'R-Squared': 0.878939139130781, 'Adjusted R-Squared': 0.8689384593198456, 'RMSE': 26201.057268267265, 'Time taken': 0.0731809139251709}\n",
      "{'Model': 'PoissonRegressor', 'R-Squared': 0.9374663365149554, 'Adjusted R-Squared': 0.9323005121401039, 'RMSE': 18831.02125425999, 'Time taken': 0.02381587028503418}\n",
      "QuantileRegressor model failed to execute\n",
      "Solver interior-point is not anymore available in SciPy >= 1.11.0.\n",
      "{'Model': 'RANSACRegressor', 'R-Squared': 0.8351739403354053, 'Adjusted R-Squared': 0.8215578745370257, 'RMSE': 30572.424114831618, 'Time taken': 0.09431099891662598}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|██████████████████████████████████▊        | 34/42 [00:06<00:02,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'RandomForestRegressor', 'R-Squared': 0.9337837585543816, 'Adjusted R-Squared': 0.9283137212175696, 'RMSE': 19377.564909271, 'Time taken': 1.8446180820465088}\n",
      "{'Model': 'Ridge', 'R-Squared': 0.8905579055333745, 'Adjusted R-Squared': 0.8815170368600447, 'RMSE': 24912.03098328307, 'Time taken': 0.00689387321472168}\n",
      "{'Model': 'RidgeCV', 'R-Squared': 0.8906336459698776, 'Adjusted R-Squared': 0.8815990341152153, 'RMSE': 24903.409188004807, 'Time taken': 0.01387476921081543}\n",
      "{'Model': 'SGDRegressor', 'R-Squared': 0.8908225463094501, 'Adjusted R-Squared': 0.8818035392654482, 'RMSE': 24881.892993283003, 'Time taken': 0.007057905197143555}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▉    | 38/42 [00:06<00:00,  5.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'SVR', 'R-Squared': -0.04913232660463729, 'Adjusted R-Squared': -0.13579977967197676, 'RMSE': 77131.55233008314, 'Time taken': 0.29587388038635254}\n",
      "{'Model': 'TransformedTargetRegressor', 'R-Squared': 0.8905527933675629, 'Adjusted R-Squared': 0.8815115023848833, 'RMSE': 24912.61281126493, 'Time taken': 0.013633966445922852}\n",
      "{'Model': 'TweedieRegressor', 'R-Squared': 0.8580437264601373, 'Adjusted R-Squared': 0.846316903863366, 'RMSE': 28372.279700441624, 'Time taken': 0.01320505142211914}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████▉ | 41/42 [00:06<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'XGBRegressor', 'R-Squared': 0.9319907848481749, 'Adjusted R-Squared': 0.9263726322921546, 'RMSE': 19638.161123697708, 'Time taken': 0.2941868305206299}\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4229\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 178675.235235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 42/42 [00:07<00:00,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Model': 'LGBMRegressor', 'R-Squared': 0.9425369845073729, 'Adjusted R-Squared': 0.9377900397492863, 'RMSE': 18051.410557448067, 'Time taken': 0.2842268943786621}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = list(housing_coords.select_dtypes(exclude=[object]))\n",
    "features.remove('SalePrice')\n",
    "X = housing_coords[features]\n",
    "y = housing_coords['SalePrice']\n",
    "\n",
    "reg = LazyRegressor(verbose=1, ignore_warnings=False, custom_metric=None)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "model_dict = {}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    models, predictions = reg.fit(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    # Save the models in a dictionary\n",
    "    model_dict[f'model_{i+1}'] = models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "dac4c47d-fb9e-4c95-82d4-b1695bff00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_dict['model_1']\n",
    "model_1.drop('Time Taken',axis=1,inplace=True)\n",
    "model_1 = model_1.rename(columns=lambda x: f\"{x}_Fold_1\")\n",
    "\n",
    "model_2 = model_dict['model_2']\n",
    "model_2.drop('Time Taken',axis=1,inplace=True)\n",
    "model_2 = model_2.rename(columns=lambda x: f\"{x}_Fold_2\")\n",
    "\n",
    "model_3 = model_dict['model_3']\n",
    "model_3.drop('Time Taken',axis=1,inplace=True)\n",
    "model_3 = model_3.rename(columns=lambda x: f\"{x}_Fold_3\")\n",
    "\n",
    "model_4 = model_dict['model_4']\n",
    "model_4.drop('Time Taken',axis=1,inplace=True)\n",
    "model_4 = model_4.rename(columns=lambda x: f\"{x}_Fold_4\")\n",
    "\n",
    "model_5 = model_dict['model_5']\n",
    "model_5.drop('Time Taken',axis=1,inplace=True)\n",
    "model_5 = model_5.rename(columns=lambda x: f\"{x}_Fold_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d126c9b4-7b9e-4394-8a51-5bb778f5229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = model_1.join(model_2).join(model_3).join(model_4).join(model_5)\n",
    "all_models = all_models.sort_index(axis=1)\n",
    "all_models.drop('RANSACRegressor',axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "c91f0e3c-410d-4e0c-9f14-ce70965e5c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Adj_R2</th>\n",
       "      <th>Mean_R2</th>\n",
       "      <th>Mean_RMSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.910398</td>\n",
       "      <td>0.917229</td>\n",
       "      <td>21760.953416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.908274</td>\n",
       "      <td>0.915267</td>\n",
       "      <td>21938.025303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.909988</td>\n",
       "      <td>0.916849</td>\n",
       "      <td>20934.547580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.897981</td>\n",
       "      <td>0.905758</td>\n",
       "      <td>22756.025296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.903117</td>\n",
       "      <td>0.910502</td>\n",
       "      <td>21932.162244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.894160</td>\n",
       "      <td>0.902229</td>\n",
       "      <td>23161.802346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.881336</td>\n",
       "      <td>0.890382</td>\n",
       "      <td>24628.655686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoCV</th>\n",
       "      <td>0.862952</td>\n",
       "      <td>0.873401</td>\n",
       "      <td>26824.483250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsCV</th>\n",
       "      <td>0.862958</td>\n",
       "      <td>0.873406</td>\n",
       "      <td>26823.743649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LarsCV</th>\n",
       "      <td>0.839265</td>\n",
       "      <td>0.851521</td>\n",
       "      <td>29063.629971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLarsIC</th>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.873639</td>\n",
       "      <td>26798.901507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LassoLars</th>\n",
       "      <td>0.861246</td>\n",
       "      <td>0.871824</td>\n",
       "      <td>26907.295557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.861236</td>\n",
       "      <td>0.871815</td>\n",
       "      <td>26907.593015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lars</th>\n",
       "      <td>0.861084</td>\n",
       "      <td>0.871675</td>\n",
       "      <td>26949.012312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.861216</td>\n",
       "      <td>0.871796</td>\n",
       "      <td>26908.628035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeCV</th>\n",
       "      <td>0.861030</td>\n",
       "      <td>0.871625</td>\n",
       "      <td>26914.343651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BayesianRidge</th>\n",
       "      <td>0.860846</td>\n",
       "      <td>0.871454</td>\n",
       "      <td>26921.610191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.868163</td>\n",
       "      <td>27072.976918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TransformedTargetRegressor</th>\n",
       "      <td>0.857283</td>\n",
       "      <td>0.868163</td>\n",
       "      <td>27072.976918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDRegressor</th>\n",
       "      <td>0.852864</td>\n",
       "      <td>0.864081</td>\n",
       "      <td>27321.659728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.837136</td>\n",
       "      <td>0.849552</td>\n",
       "      <td>29244.821120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuitCV</th>\n",
       "      <td>0.812776</td>\n",
       "      <td>0.827050</td>\n",
       "      <td>30681.152369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoostRegressor</th>\n",
       "      <td>0.807854</td>\n",
       "      <td>0.822503</td>\n",
       "      <td>30643.406548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.818379</td>\n",
       "      <td>0.832224</td>\n",
       "      <td>29562.683908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeRegressor</th>\n",
       "      <td>0.758605</td>\n",
       "      <td>0.777009</td>\n",
       "      <td>35495.443573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OrthogonalMatchingPursuit</th>\n",
       "      <td>0.765136</td>\n",
       "      <td>0.783042</td>\n",
       "      <td>33967.203830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TweedieRegressor</th>\n",
       "      <td>0.791864</td>\n",
       "      <td>0.807730</td>\n",
       "      <td>31534.554688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreeRegressor</th>\n",
       "      <td>0.725606</td>\n",
       "      <td>0.746525</td>\n",
       "      <td>36397.850460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberRegressor</th>\n",
       "      <td>0.716209</td>\n",
       "      <td>0.737834</td>\n",
       "      <td>32055.449955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassiveAggressiveRegressor</th>\n",
       "      <td>0.615997</td>\n",
       "      <td>0.645253</td>\n",
       "      <td>34343.459076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNetCV</th>\n",
       "      <td>0.105366</td>\n",
       "      <td>0.173577</td>\n",
       "      <td>68283.188364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DummyRegressor</th>\n",
       "      <td>-0.083307</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>75002.205877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NuSVR</th>\n",
       "      <td>-0.093298</td>\n",
       "      <td>-0.009940</td>\n",
       "      <td>75426.239163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>-0.145020</td>\n",
       "      <td>-0.057720</td>\n",
       "      <td>77163.667653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonRegressor</th>\n",
       "      <td>0.125559</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>35531.794595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GammaRegressor</th>\n",
       "      <td>-0.683717</td>\n",
       "      <td>-0.555487</td>\n",
       "      <td>47062.931477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianProcessRegressor</th>\n",
       "      <td>-5.102437</td>\n",
       "      <td>-4.637201</td>\n",
       "      <td>174006.761274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KernelRidge</th>\n",
       "      <td>-5.675539</td>\n",
       "      <td>-5.166618</td>\n",
       "      <td>180299.909116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLPRegressor</th>\n",
       "      <td>-6.128521</td>\n",
       "      <td>-5.585057</td>\n",
       "      <td>188067.645415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVR</th>\n",
       "      <td>-6.397684</td>\n",
       "      <td>-5.833698</td>\n",
       "      <td>191648.647621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Mean_Adj_R2   Mean_R2     Mean_RMSE\n",
       "Model                                                             \n",
       "HistGradientBoostingRegressor     0.910398  0.917229  21760.953416\n",
       "LGBMRegressor                     0.908274  0.915267  21938.025303\n",
       "GradientBoostingRegressor         0.909988  0.916849  20934.547580\n",
       "XGBRegressor                      0.897981  0.905758  22756.025296\n",
       "ExtraTreesRegressor               0.903117  0.910502  21932.162244\n",
       "RandomForestRegressor             0.894160  0.902229  23161.802346\n",
       "BaggingRegressor                  0.881336  0.890382  24628.655686\n",
       "LassoCV                           0.862952  0.873401  26824.483250\n",
       "LassoLarsCV                       0.862958  0.873406  26823.743649\n",
       "LarsCV                            0.839265  0.851521  29063.629971\n",
       "LassoLarsIC                       0.863210  0.873639  26798.901507\n",
       "LassoLars                         0.861246  0.871824  26907.295557\n",
       "Lasso                             0.861236  0.871815  26907.593015\n",
       "Lars                              0.861084  0.871675  26949.012312\n",
       "Ridge                             0.861216  0.871796  26908.628035\n",
       "RidgeCV                           0.861030  0.871625  26914.343651\n",
       "BayesianRidge                     0.860846  0.871454  26921.610191\n",
       "LinearRegression                  0.857283  0.868163  27072.976918\n",
       "TransformedTargetRegressor        0.857283  0.868163  27072.976918\n",
       "SGDRegressor                      0.852864  0.864081  27321.659728\n",
       "KNeighborsRegressor               0.837136  0.849552  29244.821120\n",
       "OrthogonalMatchingPursuitCV       0.812776  0.827050  30681.152369\n",
       "AdaBoostRegressor                 0.807854  0.822503  30643.406548\n",
       "ElasticNet                        0.818379  0.832224  29562.683908\n",
       "DecisionTreeRegressor             0.758605  0.777009  35495.443573\n",
       "OrthogonalMatchingPursuit         0.765136  0.783042  33967.203830\n",
       "TweedieRegressor                  0.791864  0.807730  31534.554688\n",
       "ExtraTreeRegressor                0.725606  0.746525  36397.850460\n",
       "HuberRegressor                    0.716209  0.737834  32055.449955\n",
       "PassiveAggressiveRegressor        0.615997  0.645253  34343.459076\n",
       "ElasticNetCV                      0.105366  0.173577  68283.188364\n",
       "DummyRegressor                   -0.083307 -0.000711  75002.205877\n",
       "NuSVR                            -0.093298 -0.009940  75426.239163\n",
       "SVR                              -0.145020 -0.057720  77163.667653\n",
       "PoissonRegressor                  0.125559  0.192157  35531.794595\n",
       "GammaRegressor                   -0.683717 -0.555487  47062.931477\n",
       "GaussianProcessRegressor         -5.102437 -4.637201 174006.761274\n",
       "KernelRidge                      -5.675539 -5.166618 180299.909116\n",
       "MLPRegressor                     -6.128521 -5.585057 188067.645415\n",
       "LinearSVR                        -6.397684 -5.833698 191648.647621"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_models['Mean_Adj_R2'] = all_models[['Adjusted R-Squared_Fold_1','Adjusted R-Squared_Fold_1','Adjusted R-Squared_Fold_3',\n",
    "                           'Adjusted R-Squared_Fold_4','Adjusted R-Squared_Fold_5']].mean(axis=1)\n",
    "all_models['Mean_R2'] = all_models[['R-Squared_Fold_1','R-Squared_Fold_1','R-Squared_Fold_3',\n",
    "                           'R-Squared_Fold_4','R-Squared_Fold_5']].mean(axis=1)\n",
    "all_models['Mean_RMSE'] = all_models[['RMSE_Fold_1', 'RMSE_Fold_2', 'RMSE_Fold_3', 'RMSE_Fold_4', 'RMSE_Fold_5', ]].mean(axis=1)\n",
    "all_models[['Mean_Adj_R2','Mean_R2','Mean_RMSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "82e9a6bf-1071-4a1b-8657-0fbdb3abf6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold R^2: 0.9139\n",
      "Fold R^2: 0.9090\n",
      "Fold R^2: 0.9101\n",
      "Fold R^2: 0.9226\n",
      "Fold R^2: 0.9481\n",
      "Average R^2: 0.9208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "# Assuming your target variable is in the 'target_column' column\n",
    "target_column = 'SalePrice'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = housing_coords.drop(target_column, axis=1)\n",
    "y = housing_coords[target_column]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)),])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features),])\n",
    "\n",
    "# Create a pipeline with preprocessor and the HistGradientBoostingRegressor model\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('regressor', HistGradientBoostingRegressor(random_state=42))])\n",
    "\n",
    "r2_scorelist = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Loop over each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate R-squared for this fold\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    r2_scorelist.append(r2)\n",
    "\n",
    "    print(f\"Fold R^2: {r2:.4f}\")\n",
    "    \n",
    "average_r2 = np.mean(r2_scorelist)\n",
    "print(f\"Average R^2: {average_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "059de681-1650-49f3-9dbe-de033c404cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4585\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 214\n",
      "[LightGBM] [Info] Start training from score 179171.023535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002650 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4586\n",
      "[LightGBM] [Info] Number of data points in the train set: 1997, number of used features: 212\n",
      "[LightGBM] [Info] Start training from score 178539.954932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4581\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 215\n",
      "[LightGBM] [Info] Start training from score 178177.698699\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4577\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 213\n",
      "[LightGBM] [Info] Start training from score 177839.309309\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4587\n",
      "[LightGBM] [Info] Number of data points in the train set: 1998, number of used features: 216\n",
      "[LightGBM] [Info] Start training from score 178028.209209\n"
     ]
    }
   ],
   "source": [
    "# Assuming your target variable is in the 'SalePrice' column\n",
    "target_column = 'SalePrice'\n",
    "\n",
    "# Separate features and target variable\n",
    "X = housing_coords.drop(target_column, axis=1)\n",
    "y = housing_coords[target_column]\n",
    "\n",
    "# Identify numerical and categorical features\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numerical and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())  # Adding StandardScaler for scaling numerical features\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                                          ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False)),])\n",
    "\n",
    "# Combine transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_transformer, numerical_features),\n",
    "                                               ('cat', categorical_transformer, categorical_features),])\n",
    "\n",
    "# Models to loop through\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'HistGradientBoostingRegressor': HistGradientBoostingRegressor(),\n",
    "    'LGBMRegressor': LGBMRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'XGBRegressor': XGBRegressor(),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "    'RandomForestRegressor': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Loop over each model\n",
    "for model_name, model in models.items():\n",
    "    # print(f\"\\nTraining {model_name} model\")\n",
    "    \n",
    "    # Create a pipeline with preprocessor and the current model\n",
    "    full_model = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', model)])\n",
    "    \n",
    "    r2_scorelist = []\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=99)\n",
    "    \n",
    "    # Loop over each fold\n",
    "    for fold, (train_index, test_index) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # Fit the model on the training data\n",
    "        full_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on the test data\n",
    "        y_pred = full_model.predict(X_test)\n",
    "        \n",
    "        # Calculate R-squared for this fold\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        r2_scorelist.append(r2)\n",
    "\n",
    "        # Append results to the list\n",
    "        results_list.append({'Model': model_name, 'Fold': fold, 'R2': r2})\n",
    "        \n",
    "        # print(f\"{model_name} - Fold {fold} - R^2: {r2:.4f}\")\n",
    "\n",
    "    # Calculate and print the average R-squared across folds for the current model\n",
    "    average_r2 = np.mean(r2_scorelist)\n",
    "    # print(f\"{model_name} - Average R^2: {average_r2:.4f}\")\n",
    "\n",
    "# Create the overall results DataFrame\n",
    "results_df_temp2 = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "07064cff-20cb-42ec-95fd-ed146e579eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.910956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.925309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.934819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1</td>\n",
       "      <td>0.903185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>2</td>\n",
       "      <td>0.922622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>3</td>\n",
       "      <td>0.922717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>5</td>\n",
       "      <td>0.932708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>2</td>\n",
       "      <td>0.923402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>3</td>\n",
       "      <td>0.926177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>5</td>\n",
       "      <td>0.936057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>2</td>\n",
       "      <td>0.868163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>3</td>\n",
       "      <td>0.890415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>5</td>\n",
       "      <td>0.913406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.909044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.910140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HistGradientBoostingRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.948138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.914165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.910282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.905267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.926605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.945837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.915838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.944970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.892705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.901411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.918309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.909209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.939632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.885669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.891859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.920054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>1</td>\n",
       "      <td>0.890589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>2</td>\n",
       "      <td>0.888830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>3</td>\n",
       "      <td>0.896494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.912640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>5</td>\n",
       "      <td>0.931751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model  Fold       R2\n",
       "0               Linear Regression     1 0.910956\n",
       "1               Linear Regression     2 0.923333\n",
       "2               Linear Regression     3 0.925751\n",
       "3               Linear Regression     4 0.925309\n",
       "4               Linear Regression     5 0.934819\n",
       "5                           Lasso     1 0.903185\n",
       "6                           Lasso     2 0.922622\n",
       "7                           Lasso     3 0.922717\n",
       "8                           Lasso     4 0.926668\n",
       "9                           Lasso     5 0.932708\n",
       "10                          Ridge     1 0.913029\n",
       "11                          Ridge     2 0.923402\n",
       "12                          Ridge     3 0.926177\n",
       "13                          Ridge     4 0.926668\n",
       "14                          Ridge     5 0.936057\n",
       "15                     ElasticNet     1 0.871826\n",
       "16                     ElasticNet     2 0.868163\n",
       "17                     ElasticNet     3 0.890415\n",
       "18                     ElasticNet     4 0.894833\n",
       "19                     ElasticNet     5 0.913406\n",
       "20  HistGradientBoostingRegressor     1 0.913950\n",
       "21  HistGradientBoostingRegressor     2 0.909044\n",
       "22  HistGradientBoostingRegressor     3 0.910140\n",
       "23  HistGradientBoostingRegressor     4 0.922607\n",
       "24  HistGradientBoostingRegressor     5 0.948138\n",
       "25                  LGBMRegressor     1 0.914165\n",
       "26                  LGBMRegressor     2 0.910282\n",
       "27                  LGBMRegressor     3 0.905267\n",
       "28                  LGBMRegressor     4 0.926605\n",
       "29                  LGBMRegressor     5 0.945837\n",
       "30      GradientBoostingRegressor     1 0.901363\n",
       "31      GradientBoostingRegressor     2 0.915838\n",
       "32      GradientBoostingRegressor     3 0.918867\n",
       "33      GradientBoostingRegressor     4 0.927125\n",
       "34      GradientBoostingRegressor     5 0.944970\n",
       "35                   XGBRegressor     1 0.892705\n",
       "36                   XGBRegressor     2 0.901411\n",
       "37                   XGBRegressor     3 0.918309\n",
       "38                   XGBRegressor     4 0.909209\n",
       "39                   XGBRegressor     5 0.939632\n",
       "40            ExtraTreesRegressor     1 0.885669\n",
       "41            ExtraTreesRegressor     2 0.901000\n",
       "42            ExtraTreesRegressor     3 0.891859\n",
       "43            ExtraTreesRegressor     4 0.922943\n",
       "44            ExtraTreesRegressor     5 0.920054\n",
       "45          RandomForestRegressor     1 0.890589\n",
       "46          RandomForestRegressor     2 0.888830\n",
       "47          RandomForestRegressor     3 0.896494\n",
       "48          RandomForestRegressor     4 0.912640\n",
       "49          RandomForestRegressor     5 0.931751"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "2087d6ef-2693-4ed7-a9a3-f6e4cf6d53a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>mean_R2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.913029</td>\n",
       "      <td>0.923402</td>\n",
       "      <td>0.926177</td>\n",
       "      <td>0.926668</td>\n",
       "      <td>0.936057</td>\n",
       "      <td>0.925067</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.910956</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.925751</td>\n",
       "      <td>0.925309</td>\n",
       "      <td>0.934819</td>\n",
       "      <td>0.924034</td>\n",
       "      <td>0.007648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.901363</td>\n",
       "      <td>0.915838</td>\n",
       "      <td>0.918867</td>\n",
       "      <td>0.927125</td>\n",
       "      <td>0.944970</td>\n",
       "      <td>0.921633</td>\n",
       "      <td>0.014331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.903185</td>\n",
       "      <td>0.922622</td>\n",
       "      <td>0.922717</td>\n",
       "      <td>0.926668</td>\n",
       "      <td>0.932708</td>\n",
       "      <td>0.921580</td>\n",
       "      <td>0.009904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.913950</td>\n",
       "      <td>0.909044</td>\n",
       "      <td>0.910140</td>\n",
       "      <td>0.922607</td>\n",
       "      <td>0.948138</td>\n",
       "      <td>0.920776</td>\n",
       "      <td>0.014487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.914165</td>\n",
       "      <td>0.910282</td>\n",
       "      <td>0.905267</td>\n",
       "      <td>0.926605</td>\n",
       "      <td>0.945837</td>\n",
       "      <td>0.920431</td>\n",
       "      <td>0.014531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.892705</td>\n",
       "      <td>0.901411</td>\n",
       "      <td>0.918309</td>\n",
       "      <td>0.909209</td>\n",
       "      <td>0.939632</td>\n",
       "      <td>0.912253</td>\n",
       "      <td>0.016095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.885669</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>0.891859</td>\n",
       "      <td>0.922943</td>\n",
       "      <td>0.920054</td>\n",
       "      <td>0.904305</td>\n",
       "      <td>0.014890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.890589</td>\n",
       "      <td>0.888830</td>\n",
       "      <td>0.896494</td>\n",
       "      <td>0.912640</td>\n",
       "      <td>0.931751</td>\n",
       "      <td>0.904061</td>\n",
       "      <td>0.016193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.871826</td>\n",
       "      <td>0.868163</td>\n",
       "      <td>0.890415</td>\n",
       "      <td>0.894833</td>\n",
       "      <td>0.913406</td>\n",
       "      <td>0.887729</td>\n",
       "      <td>0.016448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fold_1   Fold_2   Fold_3   Fold_4   Fold_5  \\\n",
       "Model                                                                        \n",
       "Ridge                         0.913029 0.923402 0.926177 0.926668 0.936057   \n",
       "Linear Regression             0.910956 0.923333 0.925751 0.925309 0.934819   \n",
       "GradientBoostingRegressor     0.901363 0.915838 0.918867 0.927125 0.944970   \n",
       "Lasso                         0.903185 0.922622 0.922717 0.926668 0.932708   \n",
       "HistGradientBoostingRegressor 0.913950 0.909044 0.910140 0.922607 0.948138   \n",
       "LGBMRegressor                 0.914165 0.910282 0.905267 0.926605 0.945837   \n",
       "XGBRegressor                  0.892705 0.901411 0.918309 0.909209 0.939632   \n",
       "ExtraTreesRegressor           0.885669 0.901000 0.891859 0.922943 0.920054   \n",
       "RandomForestRegressor         0.890589 0.888830 0.896494 0.912640 0.931751   \n",
       "ElasticNet                    0.871826 0.868163 0.890415 0.894833 0.913406   \n",
       "\n",
       "                               mean_R2      std  \n",
       "Model                                            \n",
       "Ridge                         0.925067 0.007379  \n",
       "Linear Regression             0.924034 0.007648  \n",
       "GradientBoostingRegressor     0.921633 0.014331  \n",
       "Lasso                         0.921580 0.009904  \n",
       "HistGradientBoostingRegressor 0.920776 0.014487  \n",
       "LGBMRegressor                 0.920431 0.014531  \n",
       "XGBRegressor                  0.912253 0.016095  \n",
       "ExtraTreesRegressor           0.904305 0.014890  \n",
       "RandomForestRegressor         0.904061 0.016193  \n",
       "ElasticNet                    0.887729 0.016448  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = results_df_temp2.pivot(index='Model', columns='Fold', values='R2').reset_index().set_index('Model')\n",
    "pivoted_df.columns = [f'Fold_{col}' if col != 'Model' else col for col in pivoted_df.columns]\n",
    "pivoted_df['mean_R2'] = pivoted_df.mean(axis=1)\n",
    "pivoted_df['std'] = pivoted_df.std(axis=1)\n",
    "pivoted_df.sort_values(by='mean_R2',ascending=False)\n",
    "# 1st IS RANDOM STATE 42\n",
    "# 2nd IS RANDOM STATE 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1c6df401-3364-4c12-a184-1b6399f9d58e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>mean_R2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.913264</td>\n",
       "      <td>0.930880</td>\n",
       "      <td>0.931743</td>\n",
       "      <td>0.912017</td>\n",
       "      <td>0.921936</td>\n",
       "      <td>0.921968</td>\n",
       "      <td>0.008364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.922281</td>\n",
       "      <td>0.916829</td>\n",
       "      <td>0.889503</td>\n",
       "      <td>0.927495</td>\n",
       "      <td>0.916658</td>\n",
       "      <td>0.014123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.922368</td>\n",
       "      <td>0.924759</td>\n",
       "      <td>0.909309</td>\n",
       "      <td>0.894290</td>\n",
       "      <td>0.928137</td>\n",
       "      <td>0.915773</td>\n",
       "      <td>0.012493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.862372</td>\n",
       "      <td>0.932242</td>\n",
       "      <td>0.934837</td>\n",
       "      <td>0.916867</td>\n",
       "      <td>0.927130</td>\n",
       "      <td>0.914690</td>\n",
       "      <td>0.026872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.924644</td>\n",
       "      <td>0.920064</td>\n",
       "      <td>0.910095</td>\n",
       "      <td>0.879535</td>\n",
       "      <td>0.925453</td>\n",
       "      <td>0.911958</td>\n",
       "      <td>0.017108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.849159</td>\n",
       "      <td>0.931615</td>\n",
       "      <td>0.934252</td>\n",
       "      <td>0.916579</td>\n",
       "      <td>0.927227</td>\n",
       "      <td>0.911766</td>\n",
       "      <td>0.031880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.909921</td>\n",
       "      <td>0.913064</td>\n",
       "      <td>0.894234</td>\n",
       "      <td>0.871544</td>\n",
       "      <td>0.915084</td>\n",
       "      <td>0.900769</td>\n",
       "      <td>0.016350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.916998</td>\n",
       "      <td>0.907202</td>\n",
       "      <td>0.884280</td>\n",
       "      <td>0.866252</td>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.898778</td>\n",
       "      <td>0.020427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.883334</td>\n",
       "      <td>0.901953</td>\n",
       "      <td>0.895003</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>0.919235</td>\n",
       "      <td>0.895452</td>\n",
       "      <td>0.014620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.861736</td>\n",
       "      <td>0.900293</td>\n",
       "      <td>0.903978</td>\n",
       "      <td>0.866420</td>\n",
       "      <td>0.886806</td>\n",
       "      <td>0.883847</td>\n",
       "      <td>0.017188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fold_1   Fold_2   Fold_3   Fold_4   Fold_5  \\\n",
       "Model                                                                        \n",
       "Lasso                         0.913264 0.930880 0.931743 0.912017 0.921936   \n",
       "LGBMRegressor                 0.927182 0.922281 0.916829 0.889503 0.927495   \n",
       "GradientBoostingRegressor     0.922368 0.924759 0.909309 0.894290 0.928137   \n",
       "Ridge                         0.862372 0.932242 0.934837 0.916867 0.927130   \n",
       "HistGradientBoostingRegressor 0.924644 0.920064 0.910095 0.879535 0.925453   \n",
       "Linear Regression             0.849159 0.931615 0.934252 0.916579 0.927227   \n",
       "ExtraTreesRegressor           0.909921 0.913064 0.894234 0.871544 0.915084   \n",
       "XGBRegressor                  0.916998 0.907202 0.884280 0.866252 0.919156   \n",
       "RandomForestRegressor         0.883334 0.901953 0.895003 0.877737 0.919235   \n",
       "ElasticNet                    0.861736 0.900293 0.903978 0.866420 0.886806   \n",
       "\n",
       "                               mean_R2      std  \n",
       "Model                                            \n",
       "Lasso                         0.921968 0.008364  \n",
       "LGBMRegressor                 0.916658 0.014123  \n",
       "GradientBoostingRegressor     0.915773 0.012493  \n",
       "Ridge                         0.914690 0.026872  \n",
       "HistGradientBoostingRegressor 0.911958 0.017108  \n",
       "Linear Regression             0.911766 0.031880  \n",
       "ExtraTreesRegressor           0.900769 0.016350  \n",
       "XGBRegressor                  0.898778 0.020427  \n",
       "RandomForestRegressor         0.895452 0.014620  \n",
       "ElasticNet                    0.883847 0.017188  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = results_df_temp2.pivot(index='Model', columns='Fold', values='R2').reset_index().set_index('Model')\n",
    "pivoted_df.columns = [f'Fold_{col}' if col != 'Model' else col for col in pivoted_df.columns]\n",
    "pivoted_df['mean_R2'] = pivoted_df.mean(axis=1)\n",
    "pivoted_df['std'] = pivoted_df.std(axis=1)\n",
    "pivoted_df.sort_values(by='mean_R2',ascending=False)\n",
    "# THIS IS RANDOM STATE 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "18a3d8c8-7201-4334-b8ac-a9fa60f3f1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Fold_2</th>\n",
       "      <th>Fold_3</th>\n",
       "      <th>Fold_4</th>\n",
       "      <th>Fold_5</th>\n",
       "      <th>mean_R2</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.910867</td>\n",
       "      <td>0.931169</td>\n",
       "      <td>0.931906</td>\n",
       "      <td>0.912107</td>\n",
       "      <td>0.921945</td>\n",
       "      <td>0.921599</td>\n",
       "      <td>0.008980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GradientBoostingRegressor</th>\n",
       "      <td>0.922835</td>\n",
       "      <td>0.923571</td>\n",
       "      <td>0.909933</td>\n",
       "      <td>0.894298</td>\n",
       "      <td>0.927426</td>\n",
       "      <td>0.915613</td>\n",
       "      <td>0.012179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.862502</td>\n",
       "      <td>0.932454</td>\n",
       "      <td>0.934829</td>\n",
       "      <td>0.916900</td>\n",
       "      <td>0.927196</td>\n",
       "      <td>0.914776</td>\n",
       "      <td>0.026855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.921061</td>\n",
       "      <td>0.919080</td>\n",
       "      <td>0.913728</td>\n",
       "      <td>0.888542</td>\n",
       "      <td>0.929083</td>\n",
       "      <td>0.914299</td>\n",
       "      <td>0.013791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.924644</td>\n",
       "      <td>0.920059</td>\n",
       "      <td>0.910097</td>\n",
       "      <td>0.879535</td>\n",
       "      <td>0.925440</td>\n",
       "      <td>0.911955</td>\n",
       "      <td>0.017106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear Regression</th>\n",
       "      <td>0.847917</td>\n",
       "      <td>0.931775</td>\n",
       "      <td>0.934163</td>\n",
       "      <td>0.916553</td>\n",
       "      <td>0.927293</td>\n",
       "      <td>0.911540</td>\n",
       "      <td>0.032380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesRegressor</th>\n",
       "      <td>0.909372</td>\n",
       "      <td>0.910027</td>\n",
       "      <td>0.892179</td>\n",
       "      <td>0.875218</td>\n",
       "      <td>0.912225</td>\n",
       "      <td>0.899804</td>\n",
       "      <td>0.014233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBRegressor</th>\n",
       "      <td>0.910603</td>\n",
       "      <td>0.907566</td>\n",
       "      <td>0.881969</td>\n",
       "      <td>0.865646</td>\n",
       "      <td>0.925096</td>\n",
       "      <td>0.898176</td>\n",
       "      <td>0.021392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.890312</td>\n",
       "      <td>0.907240</td>\n",
       "      <td>0.894109</td>\n",
       "      <td>0.868911</td>\n",
       "      <td>0.925301</td>\n",
       "      <td>0.897175</td>\n",
       "      <td>0.018696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ElasticNet</th>\n",
       "      <td>0.853617</td>\n",
       "      <td>0.895972</td>\n",
       "      <td>0.896038</td>\n",
       "      <td>0.849463</td>\n",
       "      <td>0.880183</td>\n",
       "      <td>0.875055</td>\n",
       "      <td>0.020093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Fold_1   Fold_2   Fold_3   Fold_4   Fold_5  \\\n",
       "Model                                                                        \n",
       "Lasso                         0.910867 0.931169 0.931906 0.912107 0.921945   \n",
       "GradientBoostingRegressor     0.922835 0.923571 0.909933 0.894298 0.927426   \n",
       "Ridge                         0.862502 0.932454 0.934829 0.916900 0.927196   \n",
       "LGBMRegressor                 0.921061 0.919080 0.913728 0.888542 0.929083   \n",
       "HistGradientBoostingRegressor 0.924644 0.920059 0.910097 0.879535 0.925440   \n",
       "Linear Regression             0.847917 0.931775 0.934163 0.916553 0.927293   \n",
       "ExtraTreesRegressor           0.909372 0.910027 0.892179 0.875218 0.912225   \n",
       "XGBRegressor                  0.910603 0.907566 0.881969 0.865646 0.925096   \n",
       "RandomForestRegressor         0.890312 0.907240 0.894109 0.868911 0.925301   \n",
       "ElasticNet                    0.853617 0.895972 0.896038 0.849463 0.880183   \n",
       "\n",
       "                               mean_R2      std  \n",
       "Model                                            \n",
       "Lasso                         0.921599 0.008980  \n",
       "GradientBoostingRegressor     0.915613 0.012179  \n",
       "Ridge                         0.914776 0.026855  \n",
       "LGBMRegressor                 0.914299 0.013791  \n",
       "HistGradientBoostingRegressor 0.911955 0.017106  \n",
       "Linear Regression             0.911540 0.032380  \n",
       "ExtraTreesRegressor           0.899804 0.014233  \n",
       "XGBRegressor                  0.898176 0.021392  \n",
       "RandomForestRegressor         0.897175 0.018696  \n",
       "ElasticNet                    0.875055 0.020093  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivoted_df = results_df_temp2.pivot(index='Model', columns='Fold', values='R2').reset_index().set_index('Model')\n",
    "pivoted_df.columns = [f'Fold_{col}' if col != 'Model' else col for col in pivoted_df.columns]\n",
    "pivoted_df['mean_R2'] = pivoted_df.mean(axis=1)\n",
    "pivoted_df['std'] = pivoted_df.std(axis=1)\n",
    "pivoted_df.sort_values(by='mean_R2',ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
